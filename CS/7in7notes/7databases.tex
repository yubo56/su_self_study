    \documentclass[10pt]{article}
    \usepackage{fancyhdr, amsmath, amsthm, amssymb, mathtools, lastpage,
    hyperref, enumerate, graphicx, setspace, wasysym, upgreek, listings, times}
    % chancery
    \usepackage[margin=1in]{geometry}
    \newcommand{\scinot}[2]{#1\times10^{#2}}
    \newcommand{\bra}[1]{\left<#1\right|}
    \newcommand{\ket}[1]{\left|#1\right>}
    \newcommand{\dotp}[2]{\left<#1\,\middle|\,#2\right>}
    \newcommand{\rd}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
    \newcommand{\pd}[2]{\frac{\partial#1}{\partial#2}}
    \newcommand{\rtd}[2]{\frac{\mathrm{d}^2#1}{\mathrm{d}#2^2}}
    \newcommand{\ptd}[2]{\frac{\partial^2 #1}{\partial#2^2}}
    \newcommand{\norm}[1]{\left|\left|#1\right|\right|}
    \newcommand{\abs}[1]{\left|#1\right|}
    \newcommand{\pvec}[1]{\vec{#1}^{\,\prime}}
    \newcommand{\svec}[1]{\vec{#1}\;\!}
    \newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
    \let\Re\undefined
    \let\Im\undefined
    \newcommand{\ang}[0]{\text{\AA}}
    \newcommand{\mum}[0]{\upmu \mathrm{m}}
    \DeclareMathOperator{\Res}{Res}
    \DeclareMathOperator{\Re}{Re}
    \DeclareMathOperator{\Im}{Im}
    \DeclareMathOperator{\Log}{Log}
    \DeclareMathOperator{\Arg}{Arg}
    \DeclareMathOperator{\Tr}{Tr}
    \DeclareMathOperator{\E}{E}
    \DeclareMathOperator{\Var}{Var}
    \DeclareMathOperator*{\argmin}{argmin}
    \DeclareMathOperator*{\argmax}{argmax}
    \DeclareMathOperator{\sgn}{sgn}
    \DeclareMathOperator{\diag}{diag}
    \newcommand{\expvalue}[1]{\left<#1\right>}
    \usepackage[labelfont=bf, font=scriptsize]{caption}\usepackage{tikz}
    \usepackage[font=scriptsize]{subcaption}
    \everymath{\displaystyle}
    \lstset{basicstyle=\ttfamily\footnotesize,frame=single,numbers=left}

\tikzstyle{circ} = [draw, circle, fill=white, node distance=3cm, minimum
height=2em]

\begin{document}

\onehalfspacing

\pagestyle{fancy}
\rhead{Yubo Su}
\cfoot{\thepage/\pageref{LastPage}}

\section{Introduction}

\begin{itemize}
    \item The questions we ask of each database:
        \begin{itemize}
            \item \emph{What type of DB is this?} Relational etc.
            \item \emph{What was the motivation?} Who developed and why.
            \item \emph{How do you talk to it?} Through shell, programming,
                protocols?
            \item \emph{Why is it unique?}
            \item Performance/scalability.
        \end{itemize}
    \item Large genres of DBs:
        \begin{description}
            \item[Relational] Two-dimensional tables from set theory, queries
                are in Structured Query Language (SQL), based on relational set
                theory. PostgreSQL.\@
            \item[Key-Value] Literally a hash. Riak + Redis.
            \item[Columnar] Instead of storing rows of a table together, store
                columns together. Easy to build sparse attributes. HBase.
            \item[Document] Stores hashes of basically anything (JSON). MongoDB
                + CouchDB.\@
            \item[Graph] Stores nodes and relationships between nodes, can
                traverse along relationships effectively. Neo4J.
        \end{description}
    \item Best practice is obviously to use multiple DBs for diff use cases.
\end{itemize}

Glossary:
\begin{description}
    \item[Relational] Based on relational albegra, not based on relations
        between tables.
    \item[CRUD] Create Read Update Delete. Every other operation is a higher
        order composition of these.
    \item[REST] REpresentational State Transfer, guideline for mapping CRUD
        resources to URLs.
    \item[MapReduce] Not a new concept, but succinctly captured by \emph{It is
        faster to send the algorithm to the data than the data to the
        algorithm}. (\emph{Note: Generally best when reducing in MapReduce to
        reduce to the same schema as mapped values to allow chaining reduces.})
    \item[CAP Theorem] When a network partition error occurs and messages are
        lost in a \emph{partitioned} network, you can only guarantee
        \emph{consistency} (across partitions) or \emph{availability} to further
        incoming requests. More precisely, \emph{at any given moment in time you
        cannot be consistent, available and partition tolerant.}
\end{description}

\section{PostgreSQL}

\begin{itemize}
    \item Roots in 1970s, supported SQL by 1996. Relational. Archetypally
        stable/reliable.
    \item Relations = \lstinline{TABLE}s, attributes = \lstinline{COLUMN}s,
        tuples = \lstinline{ROW}s.
    \item On \lstinline{INSERT}, can specify \lstinline{RETURNING} to get any
        automatically populated values e.g.\ \lstinline{SERIAL} primary keys.
    \item Joins
        \begin{description}
            \item[Inner Join] Join two columns from two tables on equality of
                those columns.
            \item[Outer Join] Join two columns from two tables and for at least
                one of the two tables always return even if the lookup in the
                other table fails.
        \end{description}
    \item \emph{Indexing} helps avoid full table scans. PostgreSQL automatically
        indexes the primary key and all \lstinline{UNIQUE} attributes. Can do
        either hash or btree indexes. Also when specify \lstinline{FOREIGN KEY},
        index target table.
    \item Can \lstinline{INSERT INTO} values that are \lstinline{SELECT}ed from
        another table! Handy to prevent hardcoding primary keys everywhere.
    \item Aggregate functions allow post-processing, e.g.\ \lstinline{count()}.
        Can \lstinline{GROUP_BY} aggregate functions and can also filter on
        aggregated values with \lstinline{HAVING} the same way
        \lstinline{SELECT} filters with \lstinline{WHERE}.
    \item Can use \lstinline{PARTITION_BY} to not collapse rows within each
        group. Use case is when \lstinline{SELECT}ing over a field not used in
        an aggregate query and so can get conflicting values when also
        \lstinline{GROUP_BY}ing.
    \item Transactions + ACID compliance:
        \begin{itemize}
            \item Transactions ensure that every command of a set is executed
                else none.
            \item ACID---Atomic (all or nothing), Consistent (never stuck in
                inconsistent state e.g.\ nonexistent foreign keys), Isolated
                (transactions do not interfere), Durable (committed transactions
                will always endure even if server crashes).
        \end{itemize}
    \item Can store procedures (\lstinline{FUNCTION}s) that are loaded by the
        database side. Obviously faster than postprocessing returned data from
        the db but higher maintenance cost.
    \item Can specify \lstinline{TRIGGER}s that hit these stored procedures
    \item Lifecycle of a SQL command: parsed into query tree, modify ased off
        rules (and views, which are a specific type of rule), hit query planner,
        executed and return.
    \item Can specify custom rules e.g.\ how to interpret certain operations on
        a view.
    \item Can fuzzy string search using \lstinline{LIKE} and \lstinline{ILIKE},
        can regex or even Levenstein (edit distance), trigram. All have
        corresponding indexes that can be built, all plugable using
        PostgreSQL-exclusive packages.
    \item The \lstinline{cube} seems neat, you can define feature vectors for
        each row and tell PostgreSQL how to measure distances between feature
        vectors and query on said distance.
    \item Apparently does not scale well horizontally b/c partitioning is
        difficult for relational databases. But is very good for normalized
        data, extremely reliable w/ transactions + ACID compliance.
\end{itemize}

\section{Riak}

\begin{itemize}
    \item Riak is a highly distributed, highly available key-value DB that is
        built for a web interface, notably to be \lstinline{cURL}ed.
    \item All nodes are equal, very easy to join nodes
        \lstinline{riak-admin join}.
    \item Insert by \lstinline{curl -X PUT}, delete by
        \lstinline{curl -X DELETE}.
    \item Key format is \lstinline{<server>/<bucket>/<key>} and the key can be
        auto-generated on insertion.
    \item Can \lstinline{Link} values to metadata labels. Say that the label
        \lstinline{contains} the value. Is one-way pointer.
    \item Can query on links, called \emph{link walking}, with \lstinline{GET}
        to \lstinline{<server>/<link bucket>/<link>}. Can specify to
        \lstinline{keep} each step in the link walking.
    \item Can also tag with various other metadata, \lstinline{X-Riak-Meta-*}.
        Can also specify MIME type to store images etc.\ that are linked to
        existing entries.
    \item Can execute commands by posting JSON bodies to endpoints e.g.\
        \lstinline{/mapred}. Endpoints often take a function body in plaintext,
        so can generally point to a bucket + key instead. Stored procedures!
    \item Riak supports filtering keys prior to map reduce.
    \item The \emph{Riak Ring} is key to consistency and durability;
        \begin{itemize}
            \item All nodes are peers, growing and shrinking the cluster is
                trivial.
            \item Riak uses a 160-bit \emph{ring} hashing keys to determine
                which Riak servers store the values for which key.
            \item Riak then partitions the ring and each server claims
                partitions sequentially on startup.
            \item Riak accomplishes redundancy by hashing each key to
                \lstinline{N} nodes, considering a write successful when
                \lstinline{W} nodes have completed the write, and then you can
                specify reading from \lstinline{R} nodes.
        \end{itemize}
    \item Writes in Riak are by default not durable and not written to disk
        before acknowledgement.
    \item Riak by default 204s when writing to a server that is not yet up, and
        a neighboring node will buffer the write! Careful for \emph{cascading
        failure} when the neighboring nodes fail consecutively due to overload.
    \item Riak handles concurrent writes by effectively tagging each update w/ a
        commit history, and conflict resolution must be performed manually by
        specifying which \lstinline{Vclock}s an update overwrites.
        \begin{itemize}
            \item The commit history, called the \emph{vector clock}, is pruned
                as more updates to a value occur, configurable per bucket.
        \end{itemize}
    \item Can specify pre/post commit hooks, notably validators and/or computed
        values.
    \item Search wih Apache Solr interface, \lstinline{/solr}.
\end{itemize}

\section{HBase}

\begin{itemize}
    \item Apache HBase is made for very big data, on the order of GBs (EN:\@??
        That's really small.).
    \item HBase also uses buckets of data it calls \emph{tables}, and
        \emph{cells} that appear at the intersection of \emph{rows} and
        \emph{columns}, but is not an RDBMS at all!
    \item Built on Hadoop, strong for analytics since many features e.g.\
        versioning, compression and old data purge make it an appetizing
        prospect for data analytics.
\end{itemize}
\end{document}
