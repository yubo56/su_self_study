    \documentclass[10pt]{article}
    \usepackage{fancyhdr, amsmath, amsthm, amssymb, mathtools, lastpage,
    hyperref, enumerate, graphicx, setspace, wasysym, upgreek, listings, times}
    % chancery
    \usepackage[margin=1in]{geometry}
    \newcommand{\scinot}[2]{#1\times10^{#2}}
    \newcommand{\bra}[1]{\left<#1\right|}
    \newcommand{\ket}[1]{\left|#1\right>}
    \newcommand{\dotp}[2]{\left<#1\,\middle|\,#2\right>}
    \newcommand{\rd}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
    \newcommand{\pd}[2]{\frac{\partial#1}{\partial#2}}
    \newcommand{\rtd}[2]{\frac{\mathrm{d}^2#1}{\mathrm{d}#2^2}}
    \newcommand{\ptd}[2]{\frac{\partial^2 #1}{\partial#2^2}}
    \newcommand{\norm}[1]{\left|\left|#1\right|\right|}
    \newcommand{\abs}[1]{\left|#1\right|}
    \newcommand{\pvec}[1]{\vec{#1}^{\,\prime}}
    \newcommand{\svec}[1]{\vec{#1}\;\!}
    \newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
    \let\Re\undefined
    \let\Im\undefined
    \newcommand{\ang}[0]{\text{\AA}}
    \newcommand{\mum}[0]{\upmu \mathrm{m}}
    \DeclareMathOperator{\Res}{Res}
    \DeclareMathOperator{\Re}{Re}
    \DeclareMathOperator{\Im}{Im}
    \DeclareMathOperator{\Log}{Log}
    \DeclareMathOperator{\Arg}{Arg}
    \DeclareMathOperator{\Tr}{Tr}
    \DeclareMathOperator{\E}{E}
    \DeclareMathOperator{\Var}{Var}
    \DeclareMathOperator*{\argmin}{argmin}
    \DeclareMathOperator*{\argmax}{argmax}
    \DeclareMathOperator{\sgn}{sgn}
    \DeclareMathOperator{\diag}{diag}
    \newcommand{\expvalue}[1]{\left<#1\right>}
    \usepackage[labelfont=bf, font=scriptsize]{caption}\usepackage{tikz}
    \usepackage[font=scriptsize]{subcaption}
    \everymath{\displaystyle}
    \lstset{basicstyle=\ttfamily\footnotesize,frame=single,numbers=left}

\tikzstyle{circ} = [draw, circle, fill=white, node distance=3cm, minimum
height=2em]

\begin{document}

\onehalfspacing

\pagestyle{fancy}
\rhead{Yubo Su}
\cfoot{\thepage/\pageref{LastPage}}

\tableofcontents

\clearpage

\section{Introduction}

\begin{itemize}
    \item The questions we ask of each database:
        \begin{itemize}
            \item \emph{What type of DB is this?} Relational etc.
            \item \emph{What was the motivation?} Who developed and why.
            \item \emph{How do you talk to it?} Through shell, programming,
                protocols?
            \item \emph{Why is it unique?}
            \item Performance/scalability.
        \end{itemize}
    \item Large genres of DBs:
        \begin{description}
            \item[Relational] Two-dimensional tables from set theory, queries
                are in Structured Query Language (SQL), based on relational set
                theory. PostgreSQL.\@
            \item[Key-Value] Literally a hash. Riak + Redis.
            \item[Columnar] Instead of storing rows of a table together, store
                columns together. Easy to build sparse attributes. HBase.
            \item[Document] Stores hashes of basically anything (JSON). MongoDB
                + CouchDB.\@
            \item[Graph] Stores nodes and relationships between nodes, can
                traverse along relationships effectively. Neo4J.
        \end{description}
    \item Best practice is obviously to use multiple DBs for diff use cases.
\end{itemize}

Glossary:
\begin{description}
    \item[Relational] Based on relational albegra, not based on relations
        between tables.
    \item[CRUD] Create Read Update Delete. Every other operation is a higher
        order composition of these.
    \item[REST] REpresentational State Transfer, guideline for mapping CRUD
        resources to URLs.
    \item[MapReduce] Not a new concept, but succinctly captured by \emph{It is
        faster to send the algorithm to the data than the data to the
        algorithm}. (\emph{Note: Generally best when reducing in MapReduce to
        reduce to the same schema as mapped values to allow chaining reduces.})
    \item[CAP Theorem] When a network partition error occurs and messages are
        lost in a \emph{partitioned} network, you can only guarantee
        \emph{consistency} (across partitions) or \emph{availability} to further
        incoming requests. More precisely, \emph{at any given moment in time you
        cannot be consistent, available and partition tolerant.}
\end{description}

\section{PostgreSQL}

\begin{itemize}
    \item Roots in 1970s, supported SQL by 1996. Relational. Archetypally
        stable/reliable.
    \item Relations = \lstinline{TABLE}s, attributes = \lstinline{COLUMN}s,
        tuples = \lstinline{ROW}s.
    \item On \lstinline{INSERT}, can specify \lstinline{RETURNING} to get any
        automatically populated values e.g.\ \lstinline{SERIAL} primary keys.
    \item Joins
        \begin{description}
            \item[Inner Join] Join two columns from two tables on equality of
                those columns.
            \item[Outer Join] Join two columns from two tables and for at least
                one of the two tables always return even if the lookup in the
                other table fails.
        \end{description}
    \item \emph{Indexing} helps avoid full table scans. PostgreSQL automatically
        indexes the primary key and all \lstinline{UNIQUE} attributes. Can do
        either hash or btree indexes. Also when specify \lstinline{FOREIGN KEY},
        index target table.
    \item Can \lstinline{INSERT INTO} values that are \lstinline{SELECT}ed from
        another table! Handy to prevent hardcoding primary keys everywhere.
    \item Aggregate functions allow post-processing, e.g.\ \lstinline{count()}.
        Can \lstinline{GROUP_BY} aggregate functions and can also filter on
        aggregated values with \lstinline{HAVING} the same way
        \lstinline{SELECT} filters with \lstinline{WHERE}.
    \item Can use \lstinline{PARTITION_BY} to not collapse rows within each
        group. Use case is when \lstinline{SELECT}ing over a field not used in
        an aggregate query and so can get conflicting values when also
        \lstinline{GROUP_BY}ing.
    \item Transactions + ACID compliance:
        \begin{itemize}
            \item Transactions ensure that every command of a set is executed
                else none.
            \item ACID---Atomic (all or nothing), Consistent (never stuck in
                inconsistent state e.g.\ nonexistent foreign keys), Isolated
                (transactions do not interfere), Durable (committed transactions
                will always endure even if server crashes).
        \end{itemize}
    \item Can store procedures (\lstinline{FUNCTION}s) that are loaded by the
        database side. Obviously faster than postprocessing returned data from
        the db but higher maintenance cost.
    \item Can specify \lstinline{TRIGGER}s that hit these stored procedures
    \item Lifecycle of a SQL command: parsed into query tree, modify ased off
        rules (and views, which are a specific type of rule), hit query planner,
        executed and return.
    \item Can specify custom rules e.g.\ how to interpret certain operations on
        a view.
    \item Can fuzzy string search using \lstinline{LIKE} and \lstinline{ILIKE},
        can regex or even Levenstein (edit distance), trigram. All have
        corresponding indexes that can be built, all plugable using
        PostgreSQL-exclusive packages.
    \item The \lstinline{cube} seems neat, you can define feature vectors for
        each row and tell PostgreSQL how to measure distances between feature
        vectors and query on said distance.
    \item Apparently does not scale well horizontally b/c partitioning is
        difficult for relational databases. But is very good for normalized
        data, extremely reliable w/ transactions + ACID compliance.
\end{itemize}

\section{Riak}

\begin{itemize}
    \item Riak is a highly distributed, highly available key-value DB that is
        built for a web interface, notably to be \lstinline{cURL}ed.
    \item All nodes are equal, very easy to join nodes
        \lstinline{riak-admin join}.
    \item Insert by \lstinline{curl -X PUT}, delete by
        \lstinline{curl -X DELETE}.
    \item Key format is \lstinline{<server>/<bucket>/<key>} and the key can be
        auto-generated on insertion.
    \item Can \lstinline{Link} values to metadata labels. Say that the label
        \lstinline{contains} the value. Is one-way pointer.
    \item Can query on links, called \emph{link walking}, with \lstinline{GET}
        to \lstinline{<server>/<link bucket>/<link>}. Can specify to
        \lstinline{keep} each step in the link walking.
    \item Can also tag with various other metadata, \lstinline{X-Riak-Meta-*}.
        Can also specify MIME type to store images etc.\ that are linked to
        existing entries.
    \item Can execute commands by posting JSON bodies to endpoints e.g.\
        \lstinline{/mapred}. Endpoints often take a function body in plaintext,
        so can generally point to a bucket + key instead. Stored procedures!
    \item Riak supports filtering keys prior to map reduce.
    \item The \emph{Riak Ring} is key to consistency and durability;
        \begin{itemize}
            \item All nodes are peers, growing and shrinking the cluster is
                trivial.
            \item Riak uses a 160-bit \emph{ring} hashing keys to determine
                which Riak servers store the values for which key.
            \item Riak then partitions the ring and each server claims
                partitions sequentially on startup.
            \item Riak accomplishes redundancy by hashing each key to
                \lstinline{N} nodes, considering a write successful when
                \lstinline{W} nodes have completed the write, and then you can
                specify reading from \lstinline{R} nodes.
        \end{itemize}
    \item Writes in Riak are by default not durable and not written to disk
        before acknowledgement.
    \item Riak by default 204s when writing to a server that is not yet up, and
        a neighboring node will buffer the write! Careful for \emph{cascading
        failure} when the neighboring nodes fail consecutively due to overload.
    \item Riak handles concurrent writes by effectively tagging each update w/ a
        commit history, and conflict resolution must be performed manually by
        specifying which \lstinline{Vclock}s an update overwrites.
        \begin{itemize}
            \item The commit history, called the \emph{vector clock}, is pruned
                as more updates to a value occur, configurable per bucket.
        \end{itemize}
    \item Can specify pre/post commit hooks, notably validators and/or computed
        values.
    \item Search wih Apache Solr interface, \lstinline{/solr}.
\end{itemize}

\section{HBase}

\begin{itemize}
    \item Apache HBase is made for very big data, on the order of GBs (EN:\@??
        That's really small.).
    \item HBase also uses buckets of data it calls \emph{tables}, and
        \emph{cells} that appear at the intersection of \emph{rows} and
        \emph{columns}, but is not an RDBMS at all!
    \item Built on Hadoop, strong for analytics since many features e.g.\
        versioning, compression and old data purge make it an appetizing
        prospect for data analytics.
    \item XML configuration, by default uses temporary directory to store data
        (\lstinline{hbase.rootdir}), JRuby shell.
    \item Tables in HBase are just big maps of maps. Each key maps to a
        \emph{row} of data, which consists of maps from keys/\emph{columns} into
        uninterrupted arrays of bytes. Columns' full names consist of two parts,
        a \emph{column family} name and a \emph{column qualifier}, often
        concatenated with a colon.
    \item Use \lstinline$put <table>, <key>, [<column>, <value>, ...]$ to
        insert, and \lstinline$get <table>, <key>, [<projections>]$ to query.
    \item All entries are timestamped and chill around, baked in versioning!
        \lstinline{put} and \lstinline{get} can accept timestamps. Default 3
        versions, can set to store \lstinline{ALL_VERSIONS}.
    \item Interesting case study, Facebook's message index table:
        \begin{itemize}
            \item Row keys are user IDs.
            \item Timestamps are used as messageIDs
            \item Column qualifiers are the individual words of messages.
            \item Allows for fast searching of messages, just by looking at all
                timestamps of a given word, then querying along the row for all
                matches to each timestamp! Wow!
            \item Since messages are immutable, no reason to use versioning,
                clever overloading of timestamp!
        \end{itemize}
    \item Can make schema changes with \lstinline{alter}, but must
        \lstinline{disable} the table. Internally, creates a new column family
        and copies all data over, so extremely expensive!
    \item No formal schemas! Do not enforce certain column qualifiers to exist,
        allows unknown column qualifiers.
    \item Column families allow for different keys to be configured with
        different performance parameters.
    \item HBase operations are all atomic at the row level.
    \item Script in Ruby for larger operations e.g.\ XML streaming imports.
    \item Inbuild support for compression, Gzip, and Bloom filters for seeing
        whether a row key or a row + column exists w/o making a disk call!
    \item Scalability by assigning regions to row keys, servers own regions.
        \begin{itemize}
            \item Write-ahead log (WAL) buffers edit operations, which are batch persisted
                to disk.
            \item Track where regions are assigned with the \lstinline{.META}
                table, and assignments are done by the \emph{master} node, which can
                also be a region server.
            \item Regions allow for built-in distributed processing, operating
                over regions in parallel.
        \end{itemize}
    \item Generally keep column families per table down, colocate data that is
        often fetched together but otherwise more tables is preferred.
    \item Can use Thrift API to access remote HBase clusters.
    \item One notable weakness is that HBase is designed for scale, so using any
        fewer than five nodes is not recommended by the HBase community. Also
        does not have support for indexed columns, so have to be very clever
        about it!
\end{itemize}

\section{MongoDB}

\begin{itemize}
    \item MongoDB is highly versatile, document database and schemaless (as of
        the writing, by now you can specify validators).
    \item Powerful for being able to do ad hoc queries. Stores arbitrary JSON
        documents.
    \item Databases contain collections (similar to \emph{buckets}).
    \item Auto-generated autoincrementing \lstinline{_id} consisting of
        timestamp, client machine ID, client process ID and a 3-byte incremented
        counter.
    \item Purely JS, so syntax for operators \verb|{ $op: val }| is a bit
        verbose, but can build queries like JS objects!
        % ugh, lstinline triggers the linter b/c dollar sign...
    \item \verb|$elemMatch| is amazing, lets specify multiple criteria for a
        query on a nested field in Mongo.
    \item Can pass code into most mongo functions, and especially into
        \verb|$where| blocks!
    \item Indexing is done in a B-tree. \lstinline{db.coll.ensureIndex()}.
    \item Can also \lstinline{db.coll.[distinct, group]()}.
    \item Turns out that most of the magic we execute on Mongo are actually
        commands sent to the server and executed on the server side, aliased via
        the \verb|$cmd| collection. Can replicate with \lstinline{db.eval}.
    \item Map reduce is also doable, can store the results to a collection as a
        materialized view or print inline.
    \item Replica sets + sharding provide durability + scale.
        \begin{itemize}
            \item Replica sets are master-slave, writes and reads only through
                master by default.
            \item Elections when master fails, can drop data.
            \item So writes can drop when master fails; solve by requiring
                majority of nodes written before considered written.
        \end{itemize}
    \item Multi-master is difficult to resolve conflicts, Mongo simply
        disallows, vs.\ Riak where we did manual conflict resolution.
    \item Use a \lstinline{mongos} to connect to a \lstinline{mongoconfig}
        config server and track sharding configuration. Can \lstinline{mongo}
        into a \lstinline{mongos} instance and use normally, sharding is handled
        behind the scenes!
    \item Can use \lstinline${ location: "2d" }$ \lstinline{ensureIndex}es, then
        can use the \verb|$near| operator to get an indexed query \emph{near} a
        point in 2D space!
\end{itemize}

\section{CouchDB}

\begin{itemize}
    \item JSON + REST document-oriented database, robust under network failure,
        scales to all sizes. No ad-hoc querying though vs.\ Mongo.
\end{itemize}
\end{document}
