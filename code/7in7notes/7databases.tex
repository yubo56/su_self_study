    \documentclass[10pt]{article}
    \usepackage{fancyhdr, amsmath, amsthm, amssymb, mathtools, lastpage,
    hyperref, enumerate, graphicx, setspace, wasysym, upgreek, listings, times}
    % chancery
    \usepackage[margin=1in]{geometry}
    \newcommand{\scinot}[2]{#1\times10^{#2}}
    \newcommand{\bra}[1]{\left<#1\right|}
    \newcommand{\ket}[1]{\left|#1\right>}
    \newcommand{\dotp}[2]{\left<#1\,\middle|\,#2\right>}
    \newcommand{\rd}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
    \newcommand{\pd}[2]{\frac{\partial#1}{\partial#2}}
    \newcommand{\rtd}[2]{\frac{\mathrm{d}^2#1}{\mathrm{d}#2^2}}
    \newcommand{\ptd}[2]{\frac{\partial^2 #1}{\partial#2^2}}
    \newcommand{\norm}[1]{\left|\left|#1\right|\right|}
    \newcommand{\abs}[1]{\left|#1\right|}
    \newcommand{\pvec}[1]{\vec{#1}^{\,\prime}}
    \newcommand{\svec}[1]{\vec{#1}\;\!}
    \newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
    \let\Re\undefined
    \let\Im\undefined
    \newcommand{\ang}[0]{\text{\AA}}
    \newcommand{\mum}[0]{\upmu \mathrm{m}}
    \DeclareMathOperator{\Res}{Res}
    \DeclareMathOperator{\Re}{Re}
    \DeclareMathOperator{\Im}{Im}
    \DeclareMathOperator{\Log}{Log}
    \DeclareMathOperator{\Arg}{Arg}
    \DeclareMathOperator{\Tr}{Tr}
    \DeclareMathOperator{\E}{E}
    \DeclareMathOperator{\Var}{Var}
    \DeclareMathOperator*{\argmin}{argmin}
    \DeclareMathOperator*{\argmax}{argmax}
    \DeclareMathOperator{\sgn}{sgn}
    \DeclareMathOperator{\diag}{diag}
    \newcommand{\expvalue}[1]{\left<#1\right>}
    \usepackage[labelfont=bf, font=scriptsize]{caption}\usepackage{tikz}
    \usepackage[font=scriptsize]{subcaption}
    \everymath{\displaystyle}
    \lstset{basicstyle=\ttfamily\footnotesize,frame=single,numbers=left}

\tikzstyle{circ} = [draw, circle, fill=white, node distance=3cm, minimum
height=2em]

\begin{document}

\onehalfspacing

\pagestyle{fancy}
\rhead{Yubo Su}
\cfoot{\thepage/\pageref{LastPage}}

\tableofcontents

\clearpage

\section{Introduction}

\begin{itemize}
    \item The questions we ask of each database:
        \begin{itemize}
            \item \emph{What type of DB is this?} Relational etc.
            \item \emph{What was the motivation?} Who developed and why.
            \item \emph{How do you talk to it?} Through shell, programming,
                protocols?
            \item \emph{Why is it unique?}
            \item Performance/scalability.
        \end{itemize}
    \item Large genres of DBs:
        \begin{description}
            \item[Relational] Two-dimensional tables from set theory, queries
                are in Structured Query Language (SQL), based on relational set
                theory. PostgreSQL.\@
            \item[Key-Value] Literally a hash. Riak + Redis.
            \item[Columnar] Instead of storing rows of a table together, store
                columns together. Easy to build sparse attributes. HBase.
            \item[Document] Stores hashes of basically anything (JSON). MongoDB
                + CouchDB.\@
            \item[Graph] Stores nodes and relationships between nodes, can
                traverse along relationships effectively. Neo4J.
        \end{description}
    \item Best practice is obviously to use multiple DBs for diff use cases.
\end{itemize}

Glossary:
\begin{description}
    \item[Relational] Based on relational albegra, not based on relations
        between tables.
    \item[CRUD] Create Read Update Delete. Every other operation is a higher
        order composition of these.
    \item[REST] REpresentational State Transfer, guideline for mapping CRUD
        resources to URLs.
    \item[MapReduce] Not a new concept, but succinctly captured by \emph{It is
        faster to send the algorithm to the data than the data to the
        algorithm}. (\emph{Note: Generally best when reducing in MapReduce to
        reduce to the same schema as mapped values to allow chaining reduces.})
    \item[CAP Theorem] When a network partition error occurs and messages are
        lost in a \emph{partitioned} network, you can only guarantee
        \emph{consistency} (across partitions) or \emph{availability} to further
        incoming requests. More precisely, \emph{at any given moment in time you
        cannot be consistent, available and partition tolerant.}
\end{description}

\section{PostgreSQL}

\begin{itemize}
    \item Roots in 1970s, supported SQL by 1996. Relational. Archetypally
        stable/reliable.
    \item Relations = \lstinline{TABLE}s, attributes = \lstinline{COLUMN}s,
        tuples = \lstinline{ROW}s.
    \item On \lstinline{INSERT}, can specify \lstinline{RETURNING} to get any
        automatically populated values e.g.\ \lstinline{SERIAL} primary keys.
    \item Joins
        \begin{description}
            \item[Inner Join] Join two columns from two tables on equality of
                those columns.
            \item[Outer Join] Join two columns from two tables and for at least
                one of the two tables always return even if the lookup in the
                other table fails.
        \end{description}
    \item \emph{Indexing} helps avoid full table scans. PostgreSQL automatically
        indexes the primary key and all \lstinline{UNIQUE} attributes. Can do
        either hash or btree indexes. Also when specify \lstinline{FOREIGN KEY},
        index target table.
    \item Can \lstinline{INSERT INTO} values that are \lstinline{SELECT}ed from
        another table! Handy to prevent hardcoding primary keys everywhere.
    \item Aggregate functions allow post-processing, e.g.\ \lstinline{count()}.
        Can \lstinline{GROUP_BY} aggregate functions and can also filter on
        aggregated values with \lstinline{HAVING} the same way
        \lstinline{SELECT} filters with \lstinline{WHERE}.
    \item Can use \lstinline{PARTITION_BY} to not collapse rows within each
        group. Use case is when \lstinline{SELECT}ing over a field not used in
        an aggregate query and so can get conflicting values when also
        \lstinline{GROUP_BY}ing.
    \item Transactions + ACID compliance:
        \begin{itemize}
            \item Transactions ensure that every command of a set is executed
                else none.
            \item ACID---Atomic (all or nothing), Consistent (never stuck in
                inconsistent state e.g.\ nonexistent foreign keys), Isolated
                (transactions do not interfere), Durable (committed transactions
                will always endure even if server crashes).
        \end{itemize}
    \item Can store procedures (\lstinline{FUNCTION}s) that are loaded by the
        database side. Obviously faster than postprocessing returned data from
        the db but higher maintenance cost.
    \item Can specify \lstinline{TRIGGER}s that hit these stored procedures
    \item Lifecycle of a SQL command: parsed into query tree, modify ased off
        rules (and views, which are a specific type of rule), hit query planner,
        executed and return.
    \item Can specify custom rules e.g.\ how to interpret certain operations on
        a view.
    \item Can fuzzy string search using \lstinline{LIKE} and \lstinline{ILIKE},
        can regex or even Levenstein (edit distance), trigram. All have
        corresponding indexes that can be built, all plugable using
        PostgreSQL-exclusive packages.
    \item The \lstinline{cube} seems neat, you can define feature vectors for
        each row and tell PostgreSQL how to measure distances between feature
        vectors and query on said distance.
    \item Apparently does not scale well horizontally b/c partitioning is
        difficult for relational databases. But is very good for normalized
        data, extremely reliable w/ transactions + ACID compliance.
\end{itemize}

\section{Riak}

\begin{itemize}
    \item Riak is a highly distributed, highly available key-value DB that is
        built for a web interface, notably to be \lstinline{cURL}ed.
    \item All nodes are equal, very easy to join nodes
        \lstinline{riak-admin join}.
    \item Insert by \lstinline{curl -X PUT}, delete by
        \lstinline{curl -X DELETE}.
    \item Key format is \lstinline{<server>/<bucket>/<key>} and the key can be
        auto-generated on insertion.
    \item Can \lstinline{Link} values to metadata labels. Say that the label
        \lstinline{contains} the value. Is one-way pointer.
    \item Can query on links, called \emph{link walking}, with \lstinline{GET}
        to \lstinline{<server>/<link bucket>/<link>}. Can specify to
        \lstinline{keep} each step in the link walking.
    \item Can also tag with various other metadata, \lstinline{X-Riak-Meta-*}.
        Can also specify MIME type to store images etc.\ that are linked to
        existing entries.
    \item Can execute commands by posting JSON bodies to endpoints e.g.\
        \lstinline{/mapred}. Endpoints often take a function body in plaintext,
        so can generally point to a bucket + key instead. Stored procedures!
    \item Riak supports filtering keys prior to map reduce.
    \item The \emph{Riak Ring} is key to consistency and durability;
        \begin{itemize}
            \item All nodes are peers, growing and shrinking the cluster is
                trivial.
            \item Riak uses a 160-bit \emph{ring} hashing keys to determine
                which Riak servers store the values for which key.
            \item Riak then partitions the ring and each server claims
                partitions sequentially on startup.
            \item Riak accomplishes redundancy by hashing each key to
                \lstinline{N} nodes, considering a write successful when
                \lstinline{W} nodes have completed the write, and then you can
                specify reading from \lstinline{R} nodes.
        \end{itemize}
    \item Writes in Riak are by default not durable and not written to disk
        before acknowledgement.
    \item Riak by default 204s when writing to a server that is not yet up, and
        a neighboring node will buffer the write! Careful for \emph{cascading
        failure} when the neighboring nodes fail consecutively due to overload.
    \item Riak handles concurrent writes by effectively tagging each update w/ a
        commit history, and conflict resolution must be performed manually by
        specifying which \lstinline{Vclock}s an update overwrites.
        \begin{itemize}
            \item The commit history, called the \emph{vector clock}, is pruned
                as more updates to a value occur, configurable per bucket.
        \end{itemize}
    \item Can specify pre/post commit hooks, notably validators and/or computed
        values.
    \item Search wih Apache Solr interface, \lstinline{/solr}.
\end{itemize}

\section{HBase}

\begin{itemize}
    \item Apache HBase is made for very big data, on the order of GBs (EN:\@??
        That's really small.).
    \item HBase also uses buckets of data it calls \emph{tables}, and
        \emph{cells} that appear at the intersection of \emph{rows} and
        \emph{columns}, but is not an RDBMS at all!
    \item Built on Hadoop, strong for analytics since many features e.g.\
        versioning, compression and old data purge make it an appetizing
        prospect for data analytics.
    \item XML configuration, by default uses temporary directory to store data
        (\lstinline{hbase.rootdir}), JRuby shell.
    \item Tables in HBase are just big maps of maps. Each key maps to a
        \emph{row} of data, which consists of maps from keys/\emph{columns} into
        uninterrupted arrays of bytes. Columns' full names consist of two parts,
        a \emph{column family} name and a \emph{column qualifier}, often
        concatenated with a colon.
    \item Use \lstinline$put <table>, <key>, [<column>, <value>, ...]$ to
        insert, and \lstinline$get <table>, <key>, [<projections>]$ to query.
    \item All entries are timestamped and chill around, baked in versioning!
        \lstinline{put} and \lstinline{get} can accept timestamps. Default 3
        versions, can set to store \lstinline{ALL_VERSIONS}.
    \item Interesting case study, Facebook's message index table:
        \begin{itemize}
            \item Row keys are user IDs.
            \item Timestamps are used as messageIDs
            \item Column qualifiers are the individual words of messages.
            \item Allows for fast searching of messages, just by looking at all
                timestamps of a given word, then querying along the row for all
                matches to each timestamp! Wow!
            \item Since messages are immutable, no reason to use versioning,
                clever overloading of timestamp!
        \end{itemize}
    \item Can make schema changes with \lstinline{alter}, but must
        \lstinline{disable} the table. Internally, creates a new column family
        and copies all data over, so extremely expensive!
    \item No formal schemas! Do not enforce certain column qualifiers to exist,
        allows unknown column qualifiers.
    \item Column families allow for different keys to be configured with
        different performance parameters.
    \item HBase operations are all atomic at the row level.
    \item Script in Ruby for larger operations e.g.\ XML streaming imports.
    \item Inbuild support for compression, Gzip, and Bloom filters for seeing
        whether a row key or a row + column exists w/o making a disk call!
    \item Scalability by assigning regions to row keys, servers own regions.
        \begin{itemize}
            \item Write-ahead log (WAL) buffers edit operations, which are batch persisted
                to disk.
            \item Track where regions are assigned with the \lstinline{.META}
                table, and assignments are done by the \emph{master} node, which can
                also be a region server.
            \item Regions allow for built-in distributed processing, operating
                over regions in parallel.
        \end{itemize}
    \item Generally keep column families per table down, colocate data that is
        often fetched together but otherwise more tables is preferred.
    \item Can use Thrift API to access remote HBase clusters.
    \item One notable weakness is that HBase is designed for scale, so using any
        fewer than five nodes is not recommended by the HBase community. Also
        does not have support for indexed columns, so have to be very clever
        about it!
\end{itemize}

\section{MongoDB}

\begin{itemize}
    \item MongoDB is highly versatile, document database and schemaless (as of
        the writing, by now you can specify validators).
    \item Powerful for being able to do ad hoc queries. Stores arbitrary JSON
        documents.
    \item Databases contain collections (similar to \emph{buckets}).
    \item Auto-generated autoincrementing \lstinline{_id} consisting of
        timestamp, client machine ID, client process ID and a 3-byte incremented
        counter.
    \item Purely JS, so syntax for operators \verb|{ $op: val }| is a bit
        verbose, but can build queries like JS objects!
        % ugh, lstinline triggers the linter b/c dollar sign...
    \item \verb|$elemMatch| is amazing, lets specify multiple criteria for a
        query on a nested field in Mongo.
    \item Can pass code into most mongo functions, and especially into
        \verb|$where| blocks!
    \item Indexing is done in a B-tree. \lstinline{db.coll.ensureIndex()}.
    \item Can also \lstinline{db.coll.[distinct, group]()}.
    \item Turns out that most of the magic we execute on Mongo are actually
        commands sent to the server and executed on the server side, aliased via
        the \verb|$cmd| collection. Can replicate with \lstinline{db.eval}.
    \item Map reduce is also doable, can store the results to a collection as a
        materialized view or print inline.
    \item Replica sets + sharding provide durability + scale.
        \begin{itemize}
            \item Replica sets are master-slave, writes and reads only through
                master by default.
            \item Elections when master fails, can drop data.
            \item So writes can drop when master fails; solve by requiring
                majority of nodes written before considered written.
        \end{itemize}
    \item Multi-master is difficult to resolve conflicts, Mongo simply
        disallows, vs.\ Riak where we did manual conflict resolution.
    \item Use a \lstinline{mongos} to connect to a \lstinline{mongoconfig}
        config server and track sharding configuration. Can \lstinline{mongo}
        into a \lstinline{mongos} instance and use normally, sharding is handled
        behind the scenes!
    \item Can use \lstinline${ location: "2d" }$ \lstinline{ensureIndex}es, then
        can use the \verb|$near| operator to get an indexed query \emph{near} a
        point in 2D space!
\end{itemize}

\section{CouchDB}

\begin{itemize}
    \item JSON + REST document-oriented database, robust under network failure,
        scales to all sizes. No ad-hoc querying though vs.\ Mongo.
    \item Meant to be able to be deployed anywhere and extremely robust: the
        only way to shut it down is to kill the process! Append-only storage
        model.
    \item Behind a REST interface like Riak.
    \item From \lstinline{<server>/_utils}, can create DBs and manually insert
        documensts.
    \item Automagically assigned \lstinline{_id} field, just like Mongo.
    \item All fields that begin with an underscore have special meaning, in
        particular \lstinline{_id} and \lstinline{_rev}.
    \item To update/delete an existing document, need both \lstinline{_id} and
        \lstinline{_rev}, which is just an autoincrementing int with a uuid
        after. Can't update any revision but the latest. Prevents conflicts!
    \item Behind REST interface, \lstinline{<host>/<db>/<doc._id>}
    \item \lstinline{GET} to fetch objects, \lstinline{POST} to create,
        \lstinline{PUT} to update, \lstinline{DELETE} to delete.
    \item Views consist of a mapper and reducer that generate an ordered list of
        key-value pairs. Key is whatever the mapper emits and value is whatever
        is aggregated behind the key (often a list of \lstinline{doc._id}'s).
        Ordered by whatever key mapper emits. Built in view
        \lstinline{_all_docs}.
    \item Can \lstinline{POST} to \lstinline{_temp_view} with a body containing
        mapper and reducer! Can also persist a view as a \emph{design document}.
    \item CouchDB recursively calls the reduce function until no duplicate keys
        remain! To this end, reduce functions take
        \lstinline{(key, values, rereduce)} where the third parameter is a
        boolean describing whether it's a rereduce. Best practice dictates we
        should never need this function\dots
    \item Changes API makes it easy to keep up to date on data changes.
        \begin{itemize}
            \item \lstinline{cURL} can just hit \lstinline{<host>/<db>/_changes}
                for paginated view of changes to the db. Polling.
            \item Can also specify \lstinline{?feed=longpoll} to leave
                connection open for a while, can implement a listener on any new
                data on the connection (example in Node in book).
            \item Can also specify \lstinline{?feed=continuous} instead for
                continuous stream!
        \end{itemize}
    \item Replication:
        \begin{itemize}
            \item Supports multi-master a.k.a.\ master-master replication!
            \item Inserting a new master only copies inserts, not
                deletions/updates.
            \item If two masters get different updates, then replication starts,
                CouchDB just deterministically picks one to win and stores the
                other as a conflicted version, accessible with
                \lstinline{?conflicts=true}.
        \end{itemize}
\end{itemize}

\section{Neo4J}

\begin{itemize}
    \item Graph database! Means inherently schemaless.
    \item Terminology:
        \begin{description}
            \item[Node] Vertex between edges that may hold data as a set of
                key-values, \emph{properties}. Each node contains by default
                property \lstinline${id}$.
            \item[Relationship] Joins two nodes, labeled with a label,
                \emph{type}.
            \item[Visualization Profile] Can basically strformat a label for
                each node in the visualization, store as a profile.
        \end{description}
    \item We will learn to use Neo4j via Gremlin, a language built for graph
        traversal written in Groovy but basically a DSL\@.
    \item Gremlin loads the graph as \lstinline{g}, can do \lstinline{g.V} which
        returns \lstinline{v[i]} enumerated, or \lstinline{g.E} which returns

        \lstinline{e[i][<source node id>-<type>-><dest node id>]}.

        Index into verticies \lstinline{g.v(index)} (note, lower case for
        method). Can also filter via \lstinline$g.V.filter{it.prop=='val'}$.

    \item Retrieved verticies have member functions
        \begin{itemize}
            \item \lstinline{map()} retrieves the full map of the node.
            \item \lstinline{inE(), bothE(), outE()} retrieves list of incoming
                and outgoing edges.
        \end{itemize}

    \item Retrieved edges have member functions
        \begin{itemize}
            \item \lstinline{inV()} retrieves the incoming vertex for any edge.
        \end{itemize}
    \item Note that all these functions will automatically map if called by
        multiple results! e.g.\ \lstinline{<vertex>.in()} gets all
        \lstinline{<vertex>.inE().outV()}. Formally, operations are a series of
        \emph{pipes}, so a \emph{pipeline} can operate on any number of
        inputs/outputs.

    \item Sample query that can be built is
\begin{lstlisting}
v = g.v(0)
v.out('prop').in('prop').filter{ !it.equals(v) }
\end{lstlisting}
        which we can read to look at all other nodes that have edge
        \lstinline{prop} to the same node that \lstinline{v} has edge
        \lstinline{prop} to.
    \item To turn a pipeline into a single element, call \lstinline{next()} on
        it. Can also \lstinline{>> N} to get the first $N$ entries of a
        pipeline.
    \item Can write looping pipelines with \lstinline$loop(){<predicate>}$,
        where we can use \lstinline{it.loops} in the predicate for how many
        times the loop has executed.
    \item More useful commands
        \lstinline{dedup(), paths(), groupCount(), each()}, some more Groovy
        built-ins like \lstinline{collect(), inject()} mapreduce, define
        functions like any sensible language.
    \item CRUD done by calling \lstinline{save()} on edges/verticies (not
        pipelines, so use \lstinline{next()}!).
    \item Also has a REST interface! Not gonna note this, pretty redundant
        functionality.
    \item Can build indexes, query on them.
    \item Neo4J is ACID compliant! Transactions yay.
    \item High Availability mode is eventually consistent. Slave writes are
        enabled though, just propagates to master. Solutions for per-session
        consistency are to bind a session to a single server. In any case,
        strongest with read-dominated access patterns.
    \item Shipped with easy-to-use backup tool, can do incremental backups!
\end{itemize}

\section{Redis}

\begin{itemize}
    \item Super fast key-value store db, but supports beyond key-value store to
        advanced data structures, heavily speed-optimized. Also commonly used
        for publish-subscribe systems. Only 20k lines of source code, a very
        simple project w/ simple interface.
    \item Built in \lstinline{redis-benchmark} allows testing of conf; obviously
        very perf-emphasis from start!
    \item \lstinline{SET <key> <value>} and then \lstinline{GET <key>} from the
        \lstinline{redis-cli}
    \item \lstinline{MSET <key1> <value1> <key2> ...} and
        \lstinline{MGET <key1> <key2> ...}.
    \item \lstinline{MULTI ... EXEC} blocks form transactions, or more
        precisely, it queues the operations. Rather than SQL, where we had to
        rollback transactions, \lstinline{DISCARD} simply empties the current
        \lstinline{MULTI} queue.
    \item Redis natively supports complex data structures with \emph{extremely}
        large sizes, $2^{32}$:
        \begin{description}
            \item[Hashes] Commands generally prefixed with
                \lstinline{H}. \emph{Cannot nest}, unlike Mongo/Couch!
            \item[List] Commands prefixed with \lstinline{L, R} depending on
                which side of the list they act, so can act as both queues and
                stacks.
            \item[Blocking List] Commands prefixed with \lstinline{B}, block an
                operation until the \emph{next} value can be returned.
                Publish-subscribe!
            \item[Set] Commands prefixed with \lstinline{S}, can add to
                different sets and perform set operations on them and can even
                store the results into a new key!
            \item[Sorted Sets] Prefixed with \lstinline{Z}, sets are stored in
                sorted order by their key. Think priority queue! Built in
                operations to update the priority of each entry as well as most
                of the previous set operations.
        \end{description}
    \item Redis provides built in expiry, since it's commonly used for caching.
        Can use \lstinline{EXPIRE} to set expiry for existing entries or use
        \lstinline{SETEX} (and relatives presumably) to set with expiry. Can use
        \lstinline{TTL} to check time remaining, and can undo timeout with
        \lstinline{PERSIST}.
    \item Can \lstinline{telnet} in, or can \emph{pipeline} with \lstinline{nc}
        netcat, send multiple commands to all be executed with a single api
        call.
    \item \lstinline{SUBSCRIBE} can subscribe to a particular key, called a
        \emph{channel} for pubsub purposes. Producers \lstinline{PUBLISH} to the
        channel instead and get response of how many subscribers received the
        message.
    \item Redis has a few persistence options, the most basic being no
        persistence at all (purely in memory!). Redis also by default only saves
        occassionally, get \lstinline{LASTSAVE} to get last saved time. Can
        alter \lstinline{save} fields to say ``when there are N writes then save
        within M seconds.''
    \item Can provide more persistence via an \lstinline{appendonly} log of all
        writes that can be re-read on server crash. Can also set how often to
        append, generally \lstinline{appendfsync everysec} is used in
        \lstinline{redis.conf}.
    \item Interestingly, Redis is not natively built to be secure:
        \lstinline{requirepass} conf and \lstinline{AUTH} command access plain
        text passwords w/o debounce!
    \item Instead, provide command-level security via obscurity by renaming
        commands like \lstinline{FLUSHALL} to a random key instead!
    \item Also provides master-slave replication! Seems like no secondary
        reads/writes, just for backup.
    \item For distributed dbs, client is responsible for computing which
        distributed server a key lives on.
    \item Use Bloom filters with built in \lstinline{SETBIT, GETBIT} commands to
        do really fast membership!
\end{itemize}
\end{document}
