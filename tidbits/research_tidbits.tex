    \documentclass[12pt]{article}
    \usepackage{fancyhdr, amsmath, amsthm, amssymb, mathtools, lastpage,
    hyperref, enumerate, graphicx, setspace, wasysym, upgreek, listings,
    fouriernc, cancel}
    \usepackage[margin=1in]{geometry}
    \usepackage{float}
    \newcommand*{\scinot}[2]{#1\times10^{#2}}
    \newcommand*{\dotp}[2]{\left<#1\,\middle|\,#2\right>}
    \newcommand*{\rd}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
    \newcommand*{\pd}[2]{\frac{\partial#1}{\partial#2}}
    \newcommand*{\rdil}[2]{\mathrm{d}#1 / \mathrm{d}#2}
    \newcommand*{\pdil}[2]{\partial#1 / \partial#2}
    \newcommand*{\rtd}[2]{\frac{\mathrm{d}^2#1}{\mathrm{d}#2^2}}
    \newcommand*{\ptd}[2]{\frac{\partial^2 #1}{\partial#2^2}}
    \newcommand*{\md}[2]{\frac{\mathrm{D}#1}{\mathrm{D}#2}}
    \newcommand*{\pvec}[1]{\vec{#1}^{\,\prime}}
    \newcommand*{\svec}[1]{\vec{#1}\;\!}
    \newcommand*{\bm}[1]{\boldsymbol{\mathbf{#1}}}
    \newcommand*{\uv}[1]{\hat{\bm{#1}}}
    \newcommand*{\ang}[0]{\;\text{\AA}}
    \newcommand*{\mum}[0]{\;\upmu \mathrm{m}}
    \newcommand*{\at}[1]{\left.#1\right|}
    \newcommand*{\bra}[1]{\left<#1\right|}
    \newcommand*{\ket}[1]{\left|#1\right>}
    \newcommand*{\abs}[1]{\left|#1\right|}
    \newcommand*{\ev}[1]{\left\langle#1\right\rangle}
    \newcommand*{\p}[1]{\left(#1\right)}
    \newcommand*{\s}[1]{\left[#1\right]}
    \newcommand*{\z}[1]{\left\{#1\right\}}

    \usepackage[labelfont=bf, font=scriptsize]{caption}\usepackage{tikz}
    \usepackage[font=scriptsize]{subcaption}

    \let\Re\undefined
    \let\Im\undefined
    \DeclareMathOperator{\Res}{Res}
    \DeclareMathOperator{\Re}{Re}
    \DeclareMathOperator{\Im}{Im}
    \DeclareMathOperator{\Log}{Log}
    \DeclareMathOperator{\Arg}{Arg}
    \DeclareMathOperator{\Tr}{Tr}
    \DeclareMathOperator{\E}{E}
    \DeclareMathOperator{\Var}{Var}
    \DeclareMathOperator*{\argmin}{argmin}
    \DeclareMathOperator*{\argmax}{argmax}
    \DeclareMathOperator{\sgn}{sgn}
    \DeclareMathOperator{\arctanh}{arctanh}
    \DeclareMathOperator{\diag}{diag\;}

    \colorlet{Corr}{red}

    \tikzstyle{circ} % usage: \node[circ, placement] (label) {text};
        = [draw, circle, fill=white, node distance=3cm, minimum height=2em]
    \definecolor{commentgreen}{rgb}{0,0.6,0}
    \lstset{
        basicstyle=\ttfamily\footnotesize,
        frame=single,
        numbers=left,
        showstringspaces=false,
        keywordstyle=\color{blue},
        stringstyle=\color{purple},
        commentstyle=\color{commentgreen},
        morecomment=[l][\color{magenta}]{\#}
    }

\begin{document}

\pagestyle{fancy}
\rhead{Yubo Su --- Tidbits}
\cfoot{\thepage/\pageref{LastPage}}

Separating out research-related tidbits from non-research ones.

\tableofcontents

\section{06/29/19---Collisionless Boltzmann Equation in Galaxies: Landau Damping}

Inspired by \url{https://arxiv.org/pdf/1906.08655.pdf}. The problem is basically
formulated as thus: consider a kinetic-theoretic description of a fluid using
distribution function $f(t, x, p)$ which obeys collisionless Boltzmann equation
$\rd{f}{t} = 0$ (we use $p$ instead of $v$ to work in Hamiltonian coordinates).
Introducing a periodic perturbation to this fluid results in a singular
dispersion relation, which can be resolved via the usual Landau prescription
(consider a perturbation having grown from zero at $t=-\infty$). The dispersion
relation describes \emph{Landau damping} (or growth), in which energy from the
fluid is exchanged with the perturber.

\subsection{Linearized EOM}

The point of the paper is instead to analytically compute the impact of the
perturber on the distribution function, to quantify the \emph{scarring} of a
galaxy upon encounters with a nearby perturber. The equations of motion coupling
the distribution function and gravitational potential are given
\begin{equation}
    \rd{f}{t} = \pd{f}{t} + \z*{f, \mathcal{H}} = 0,
\end{equation}
where $\mathcal{H} = \frac{p^2}{2} + \Phi$ and $\z*{\dots}$ denotes the Poisson
bracket $\z*{f, \mathcal{H}} = \vec{\nabla}_xf \cdot \vec{\nabla}_p \mathcal{H}
- \vec{\nabla}_pf \cdot \vec{\nabla}_x\mathcal{H}$.

If we linearize for perturbation quantities $f_1, \Phi_1$ where $\Phi_1(x)$ does
not depend on the momenta, we obtain
\begin{align*}
    0 &= \pd{f_1}{t} + \z*{f_1, \mathcal{H}_0}
            - \vec{\nabla}_pf \cdot \vec{\nabla}_x \mathcal{H}_0,\\
        &= \pd{f_1}{t} + \vec{\nabla}_x f_1 \cdot \vec{p}
            - \vec{\nabla}_p f_1 \cdot \vec{\nabla}_x \Phi_0
            - \vec{\nabla}_p f_0 \cdot \vec{\nabla}_x \Phi_1.
\end{align*}
Oops welp I guess I never solved this.

\section{02/16/23---Linear Predictive Coding: Autoregressions and Fourier Transforms}

This was a simple enough inquiry initially: given a partial time series that
contains sinusoids, how do we extract the frequency? We know one way to do this
using the FFT, but there are advantages to other techniques. Courtesy of Jeremy
Goodman's pointers.

The trick has to do with autoregressions. Suppose we are looking to extract $l$
frequencies of form $e^{i \omega_m t}$, so that
\begin{equation}
    y_n = \sum\limits_m^l C_m e^{i\omega_m n \Delta t}.
\end{equation}
Thus, if we have at least $2l$ points or so, we should be able to fit for the
$2l$ DOF $C_m$ and $\omega_m$. There can be a noise term above if need be, in
which case more points will smooth out the noise.

What is the trick? Well, we compute the $l$-th order autoregression. In other
words, for each sequence of $l$ points, we can write down the expression
satisfying:
\begin{equation}
    y_n = \sum\limits_{m = 1}^l a_m y_{n - m}.
\end{equation}
With $l$-many such sequences, we have enough equations to solve for the $l$-many
unknowns $a_m$. These can be written in the matrix form:
\begin{equation}
    \begin{bmatrix}
        y_n\\
        y_{n + 1}\\
        \vdots\\
        y_{n + l}
    \end{bmatrix} =
    \begin{bmatrix}
        y_{n - 1} & y_{n - 2} & \dots & y_{n - l}\\
        y_{n} & y_{n - 1} & \dots & y_{n - l + 1}\\
        \vdots & \vdots & \dots & \vdots\\
        y_{n + l - 1} & y_{n + l - 2} & \dots & y_{n - 1}
    \end{bmatrix}
    \begin{bmatrix}
        a_1\\
        a_2\\
        \vdots\\
        a_l
    \end{bmatrix}.\label{eq:autoreg_def}
\end{equation}
These $\z{a_l}$ form the $\mathrm{AR}(l)$ autoregressive model for $y_n$.

This is great, but how do we get the frequencies, or also maybe the growth
rates? Now, we rewrite the above equation as
\begin{equation}
    0 =
    \begin{bmatrix}
        y_{n} & y_{n - 1} & \dots & y_{n - l}\\
        y_{n + 1} & y_{n} & \dots & y_{n - l + 1}\\
        \vdots & \vdots & \dots & \vdots\\
        y_{n + l} & y_{n + l - 1} & \dots & y_{n - 1}
    \end{bmatrix}
    \begin{bmatrix}
        -1\\
        a_1\\
        \vdots\\
        a_l
    \end{bmatrix} \equiv \bm{B} \cdot \vec{a}.
\end{equation}
Now, what if the $y_n$ look like $\lambda^n$ for some complex $\lambda$? Then
the $\lambda$ must satisfy
\begin{equation}
    1 - a_1\lambda - a_2\lambda^2 - \dots - a_l\lambda^l = 0.
\end{equation}
This is the characteristic equation for this $\mathrm{AR}(l)$ model. If we solve
for the roots of this equation, we get the possible values of $\lambda$ that
satisfy the model. In other words, if the $y_n = \lambda^n$ indeed, then $\bm{B}
\cdot \vec{a} = 0$ as requested above. Then, if the data are oscillatory, then
$\lambda = e^{i\omega_m}$ as requested above.

\subsection{Intuitive Understanding}

There's something slightly unintuitive here: we began by seeking the frequencies
in the $y_n$, but we eventually obtained this by solving an equation that has
\emph{nothing} to do with the $y_n$, the characteristic equation for the
$\mathrm{AR}(l)$ model! Why does this make sense?

Well, it should be noted that a particular $\mathrm{AR}(l)$ model does not
uniquely specify the $y_n$; this would be impossible, since there are only $l$
DOF in the model and $2l + 1$ in Eq.~\eqref{eq:autoreg_def}. Indeed, this
suggests that the amplitudes of the modes $C_m$, as well as the initial
normalization of the autoregressive chain ($y_{n - l}$) are free parameters. As
such, we can imagine that the $\mathrm{AR}(l)$ model permits a family of
solutions, any with the correct frequencies. In other words, we could also
imagine writing:
\begin{equation}
    \bm{B} \cdot \ket{a} = \sum\limits_{m=1}^lC_m\ket{b_m}\bra{b_m}\ket{a}.
\end{equation}

Another way to think about the characteristic equation is as exactly a
characteristic equation of a matrix. If we consider the matrix that maps the
vector
\begin{align}
    \begin{bmatrix}
        y_N\\
        y_{N - 1}\\
        \vdots\\
        y_{N - l}
    \end{bmatrix} = \bm{M}
    \begin{bmatrix}
        y_{N - 1}\\
        y_{N - 2}\\
        \vdots\\
        y_{N - l - 1}
    \end{bmatrix},
\end{align}
then it's clear that $\bm{M}$ has the form
\begin{equation}
    \bm{M} = \begin{bmatrix}
        a_1 & a_2 & \dots & a_{l - 1} & a_l\\
        1 & 0 & \dots & 0 & 0\\
        0 & 1 & \dots & 0 & 0\\
        0 & 0 & \dots & 1 & 0
    \end{bmatrix}.
\end{equation}
It's then clear $\bm{M}$ apparently has exactly the characteristic equation that
we prescribe above. This makes sense: the matrix $\bm{M}$ tells us whether a
vector-valued sequence of $y$ values is growing, decaying, or oscillating.

\textbf{As such, the final conclusion of this tidbit is this: the autoregression
is another way of expressing a Markov chain that allows us to advance the time
series. Then, note that any sequence with $y_n = z^n$ where $z$ is complex
(allowing periodic or exponential sequences) has $z$ as one of the eigenvalue of
its Markov chain matrix, or $z$ is a root of its characteristic polynomial.
Turning this on its head, if we compute the autoregression for a sequence and
find a root $w$ of its characteristic polynomial, this implies that the sequence
has a geometric component with factor $w$. Applying this to sequence with a
periodic component with frequency $\omega$, we see that $e^{i\omega \Delta t}$
must be a root of the characteristic polynomial of its autoregression.}

\section{02/21/23---Chaotic vs Diffusive Behavior}

This is a short section. Dong (and others) talk about ``chaotic tides'', where
the mode amplitude grows stochastically because the forcing occurs with random
amplitude. However, this is not chaos, but should be properly termed ``diffusive
tides.''

How can we argue for this? Well, the defining characteristic of chaos is a
positive Lyapunov exponent, i.e.\ an exponential growth rate of the separation
between two trajectories with nearly-idential initial conditions.
\begin{align}
    \delta y(t) &= y(t; y_0) - y(t; y_0 - \epsilon),\\
        &\sim \mathcal{O}(\epsilon e^{\lambda t}).
\end{align}
What is the growth rate for a random walk, or diffusive growth?

Let's adopt the simplest model for now, a discrete random walk with step size
$\pm 1$. Perhaps, for the sake of consistency, we can imagine that the step is
determined based on the current value of $x$, e.g.\ whether the rounded value of
$10^9 x$ is even or odd. Then, consider two initially adjacent $x$. It is
obvious that
\begin{equation}
    \abs{\delta x(t)} \leq 2t.
\end{equation}
So we already see that diffusive behavior is not chaotic.

But now, we have a fun little math problem. Consider two random walks starting
at $x = 0$ with step size $\pm 1$. What is the mean and variance of $\delta x$?
Well, using the usual CLT guidelines, the linearity of expectation gives
$\E\p{X_2 - X_1} = 0$ while linearity of variance gives $\Var\p{X_2 - X_1} =
2\Var(X_1) = 2t$. Thus, the separation between two walkers grows stochastically
and $\sim \sqrt{t}$. This is not chaos, where the separation grows
deterministically and $\sim \exp\p{\lambda t}$.

\section{02/23/23---Rayleigh Distribution}

\subsection{2D}

The Rayleigh distribution is commonly used for mutual inclinations. Can we
briefly give ourselves some intuition for it?

It's known that the Rayleigh distribution is the magnitude of a 2D vector with
two normally-distributed components. Thus, consider if $X$ and $Y$ are drawn
from $N\p{0, \sigma}$. Then the CDF of the magnitude $M = \sqrt{X^2 + Y^2}$ of
the vector is calculated as
\begin{align}
    F_M(m; \sigma) &= \iint\limits_{D(m)}f_U(u; \sigma)
        f_V(v; \sigma)\;\mathrm{d}u\mathrm{d}v
\end{align}
Here, $D(m)$ is the unit disc satisfying $\sqrt{u^2 + v^2} \leq m$, and $f_U =
N(0, \sigma)$ and $f_V = N(0, \sigma)$ are the PDFs of the random variables $U,
V$. Upon changing to polar coordinates and integrating:
\begin{align}
    F_M(m; \sigma) &= \int\limits_0^m 2\pi
        \frac{1}{2\pi \sigma^2}\exp\s{-\frac{u^2 + v^2}{2\sigma^2}}
            \;m'\mathrm{d}m',\\
        &= \frac{1}{\sigma^2}\int\limits_0^m m'\exp\s{-\frac{(m')^2}{2\sigma^2}}
            \;\mathrm{d}m',\\
    f_M(m; \sigma) &= \frac{m}{\sigma^2}\exp\s{-\frac{m^2}{2\sigma^2}}.
\end{align}
This is a Rayleigh distribution with width $\sigma$.

Now, if we know that two vectors have a magnitude separation that is Rayleigh
distributed (like Rayleigh distribution), and we know that they are iid, how can
we obtain their individual distributions (under the right assumptions)? Well,
let's first assume that the four vector components are all normally distributed
with $N\p{0, \sigma}$. Then their separation vector's components are also
normally distributed with:
\begin{align}
    f_{X_1 - X_2}\p{x_1 - x_2; \sigma} &= N\p{0, \sigma\sqrt{2}},\\
    f_{Y_1 - Y_2}\p{y_1 - y_2; \sigma} &= N\p{0, \sigma\sqrt{2}}.
\end{align}
Thus, the separation vector's magnitude is Rayleigh distributed with width
parameter $\sigma \sqrt{2}$. Thus, to generate a pair of vectors whose
separation magnitude is Rayleigh distributed with width $\delta$, we can just
generate the vector components from $N\p{0, \delta / \sqrt{2}}$.

To briefly comment, this obviously doesn't depend on the number of vectors, as
long as the measured Rayleigh distribution is for arbitrary pairs in the system.

\subsection{3D}

What about in 3D\@? This is just as much for my own practice with manipulating
PDFs and CDFs than anything. Consider a vector $\p{v_x, v_y, v_z}$ with all
three components drawn from $N\p{0, \sigma}$. What is the distribution of the
magnitude? Again:
\begin{align}
    F_M(m; \sigma)
        &= \frac{1}{(2\pi \sigma^2)^{3/2}}\iiint_{D(m)}
            f_{Vx}\p{v_x; \sigma}
            f_{Vy}\p{v_y; \sigma}
            f_{Vz}\p{v_z; \sigma}\;\mathrm{d}^3v,\\
        &= \frac{4\pi}{(2\pi \sigma^2)^{3/2}}\int_0^m
            e^{-(m')^2/(2\sigma^2)}\;(m')^2\mathrm{d}m',\\
    f_M(m; \sigma) &= \frac{4\pi m^2}{\p{2\pi \sigma^2}^{3/2}}
            e^{-m^2/(2\sigma^2)}.
\end{align}
This of course can easily generalize: it is clear that in N-D\@:
\begin{equation}
    f^{(N)}_M(m; \sigma)
        = \frac{S^{(N)}_m}{\p{2\pi \sigma^2}^{N / 2}}
            e^{-m^2 / (2\sigma^2)},
\end{equation}
where $S^{(N)}_m$ is the surface area of the $N$-sphere with radius $m$.

And what about the separation vector between some $\vec{v}$ and $\vec{w}$ in
3D\@? Well, each component of $\vec{v} - \vec{w}$ has distribution $N\p{0,
\sigma \sqrt{2}}$ again, so if $U = \abs{\vec{v} - \vec{w}}$, then its PDF is
\begin{align}
    f_U(u; \sigma)
        &= \frac{u^2}{\sigma^3\sqrt{4\pi}}
            e^{-m^2 / (4\sigma^2)}.
\end{align}

\section{03/15/23---Mass Loss and Binary Orbit Change}

Without kicks, Hills 1983 seems to have the best prescription. Time to revisit
this problem now that I've done it wrong literally every time I've tried to do
it.

\subsection{Brute Force Circular}

We start with a circular orbit and in the rest frame of the binary. Call the
pre-ML energy $E$ and post-ML energy $E'$. These are the sums of kinetic and
gravitational potential energies, so
\begin{align}
    E &= \frac{m_1v_1^2}{2} + \frac{m_2v_2^2}{2} - \frac{Gm_1m_2}{a},\\
    E' &= E - \frac{m_1v_1^2}{2}(1 - f) + \frac{Gm_1m_2}{a}\p{1 - f}.
\end{align}
Here, $m_1' = fm_1$ is the post-ML mass. Note then that
\begin{align}
    v_1^2 &= \p{\frac{am_2}{m_{13}}}^2\frac{Gm_{12}}{a}
        = \frac{Gm_2^2}{m_{12}a},\\
    K_{\rm cm} &= \frac{\p{(1 - f)m_1v_1}^2}{2\p{fm_1 + m_2}}.
\end{align}
Here, $K_{\rm cm}$ is the kinetic energy associated with the motion of the
post-ML binary's center of mass. To undergo unbinding, we need $f$ such that $E'
= K_{\rm cm}$, so that in the co-moving frame the binary is unbound. This is a
laborious calculation, but we can write ($f' \equiv 1 - f$ is the fraction of
mass lost from $m_1$)
\begin{align*}
    0 &= E' - K_{\rm cm},\\
        &= -\frac{Gm_1m_2}{2a}
            - \frac{m_1v_1^2}{2}f' + \frac{Gm_1m_2}{a}f'
            - \frac{\p{f'm_1v_1}^2}{2\p{fm_1 + m_2}},\\
        &= -\frac{Gm_1m_2}{2a}
            - \frac{Gm_1m_2^2}{2m_{12}a}f' + \frac{Gm_1m_2}{a}f'
            - \frac{\p{f'm_1}^2}{2\p{fm_1 + m_2}}
                \frac{Gm_2^2}{m_{12}a},\\
        &= -\frac{1}{2} - \frac{m_2}{2m_{12}}f'
            + f'
            - \frac{m_1m_2(f')^2}{2(m_{12} - f'm_1)m_{12}},\\
        &= -(m_{12} - f'm_1)m_{12}
            - m_2\p{m_{12} - f'm_1}f'
            + 2(m_{12} - f'm_1)m_{12}f'
            - m_1m_2(f')^2,\\
        &= -m_{12} + f'(m_1 - m_2 + 2m_{12})
            - 2m_1(f')^2,\\
        &= (f')^2 - \frac{f'}{2}\p{3 + \frac{m_2}{m_1}}
            + \frac{1}{2}\p{1 + \frac{m_2}{m_1}},\\
    f' &= \frac{(3 + q)/2 \pm \sqrt{(3 + q)^2/4 - 2(1+q)}}{2},\\
        &= \frac{(3 + q)/2 \pm ((q-1)/2)}{2},\\
        &= \frac{1 + q}{2},\\
        &= \frac{m_{12}}{2m_1}.
\end{align*}
Whew. This is the canonical result, that we need to lose $f'm_1 =
\frac{m_{12}}{2}$ mass to unbind the system.

\subsection{Easier Circular}

The primary difficulty above was that we had this stupid center of mass kinetic
energy to carry around. This can be simplified if we just recognize that we only
need to compute the contribution of the reduced mass to the energy to understand
whether the system remains bound. Recall that the the kinetic energy of of the
reduced mass component is just
\begin{align}
    K_{\rm red} &= \frac{\mu v_{\rm rel}^2}{2},\\
    E_{\rm red} &= K_{\rm red} - \frac{Gm_{12}\mu}{a} =
            -\frac{Gm_{12}\mu}{2a},\\
    v_{\rm rel}^2 &= \frac{Gm_{12}}{a},\\
    E_{\rm red}' &= \frac{\mu v_{\rm rel}^2}{2}
        - \frac{Gm_{12}'\mu'}{a} = 0,\\
        &= \frac{Gm_{12}\mu'}{2a} - \frac{Gm_{12}'\mu'}{a}.
\end{align}
Thus, we end up with the result that $m_{12}' = m_{12} / 2$ results in a
reduced-mass energy $= 0$ and unbinding. It's important to recognize that
$v_{\rm rel}$ is the relative velocity of the two particles, given by
$\bm{v}_{\rm rel} = \bm{v}_2 - \bm{v}_1$, which does not change with
instantaneous mass loss.

\subsection{Eccentric Unbinding}

The argument in the previous section is much easier to generalize to a general
orbit. Consider that the orbit has semimajor axis $a$ and unbinds when the
separation is at $r$. Then
\begin{align*}
    E_{\rm red} &= \frac{1}{2}\mu v_{\rm rel}^2
        - \frac{Gm_{12}\mu}{r} = -\frac{Gm_{12}\mu}{2a},\\
    \frac{v_{\rm rel}^2}{2} &= Gm_{12}\p{-\frac{1}{2a} + \frac{1}{r}},\\
    E_{\rm red}' &= \frac{1}{2}\mu' v_{\rm rel}^2 - \frac{Gm_{12}'\mu'}{r},\\
        &= \mu'\s{-\frac{Gm_{12}}{2a} + \frac{Gm_{12}}{r}}
            - \frac{Gm_{12}'\mu'}{r}.
\end{align*}
Setting this equal to zero, we find
\begin{align}
    0 &= \mu'\s{-\frac{Gm_{12}}{2a} + \frac{Gm_{12}}{r}}
            - \frac{Gm_{12}'\mu'}{r},\\
    \frac{m_{12}'}{m_{12}} &= -\frac{r}{2a} + 1.
\end{align}
If we re-express $m_{12}' \equiv m_{12} - \Delta$, then we can rewrite
\begin{align}
    1 - \frac{\Delta}{m_{12}} &= 1 - \frac{r}{2a}
        = 1 - \frac{1 - e^2}{2\p{1 + e\cos f}}.
\end{align}
This makes sense: since the mass loss effects a torque on the system, we have to
give it the maximum torque to unbind the system, which occurs at pericenter.
Thus, qualitatively we need a minimum eccentricity of $(1 - e) / 2 \sim m_{12}'
/ m_{12}$ to unbind the system of $m_{12}' > m_{12} / 2$, i.e.\ if the mass loss
is too little.

\subsection{Bound Orbits: Final Eccentricity}

Of course, these exercises can be repeated if we would like for bound orbits,
and tracking the angular momentum of the system as well to get eccentricity.
I may redo this some day, but for now I will just cite the result from Hills
1983, where the final eccentricity is given by
\begin{equation}
    e = \z{1 - (1 - e_0^2)\s{\frac{1 - (2a_0/r)(\Delta / m_{12})}{
        1 - \Delta / m_{12}}^2}}^{1/2}.
\end{equation}

\section{03/23/2023---Pendulum Periods}

It might be helpful to just do the simple pendulum in a few ways to get its
period. Specifically, I mean the oscillation of the nondimensionalized EOM
\begin{equation}
    \ddot{\theta} = -\sin\theta.
\end{equation}
In the small angle approximation $\theta \ll 1$, we have that the frequency of
the oscillator is just $1$, so the period is $2\pi$.

\subsection{Lindstedt-Poincar\'e}

I always get this wrong, so let's try again. The zeroth order solution is
$\theta = \epsilon \cos\p{\omega_0 t}$ where $\omega_0 = 1$. Let's next imagine
that the frequency has a small $\epsilon$ dependence, so that
\begin{align*}
    \theta(t) &= \epsilon \cos\p{(1 + \epsilon \omega_1)t},\\
    \ddot{\theta} &= -\epsilon \p{1 + \epsilon \omega_1}^2
            \cos\p{(1 + \epsilon \omega_1)t},\\
            &\approx -\epsilon \cos\p{(1 + \epsilon \omega_1)t}
                + \frac{1}{6}\epsilon^3 \cos^3\p{(1 + \epsilon \omega_1)t}.
\end{align*}
Using the quick identity
\begin{align*}
    \cos^3\theta &= \cos\theta - \cos\theta \sin^2\theta\\
        &= \cos\theta + \frac{\cos\theta\p{\cos 2\theta - 1}}{2}\\
        &= \frac{\cos\theta}{2} + \frac{\cos (3\theta) +
            \sin\theta\sin2\theta}{2}\\
        &= \frac{\cos\theta}{2} + \frac{\cos (3\theta)}{2} +
            \sin^2\theta\cos\theta\\
        &= -\cos^3\theta + \frac{3\cos\theta}{2} + \frac{\cos(3\theta)}{2},\\
    \cos^3\theta &= \frac{3\cos\theta}{4} + \frac{\cos(3\theta)}{4},
\end{align*}
we obtain
\begin{align*}
    -\epsilon \p{1 + \epsilon \omega_1}^2
            \cos\p{(1 + \epsilon \omega_1)t}
            &\approx -\epsilon \cos\p{(1 + \epsilon \omega_1)t}
                + \frac{1}{6}\epsilon^3 \cos^3\p{(1 + \epsilon \omega_1)t}.
\end{align*}
Matching coefficients of the first frequency term, we find
\begin{align*}
    -\epsilon\p{1 + 2\epsilon \omega_1}
        &\approx -\epsilon + \frac{\epsilon^3}{8},\\
    \omega_1 &= -\frac{\epsilon}{16},\\
    \omega &= 1 - \frac{\epsilon^2}{16}.
\end{align*}
In our Ph106b class notes, we solve the Duffing oscillator with this technique,
for which $\ddot{\theta} = -\theta - \epsilon \theta^3$ and we obtain that
$\omega = 1 + (3/8)\epsilon A^2$ for oscillation amplitude $A$. For the simple
pendulum, $\epsilon = -1/6$, and so we recover that $\omega = 1 - A^2/16$. We
didn't do this strictly correctly, I guess, since our small parameter was the
oscillation amplitude $A$ instead of the perturbing term $\epsilon$, but we
obtain the right result: \textbf{the oscillation period grows with larger
amplitude}. We can already anticipate that $\epsilon \to 4$ will produce
problems, and indeed $\epsilon = \pi$ corresponds to the upside-down pendulum.

\subsection{Explicit Integral}

The period of the pendulum can be solved exactly using the method of
quadratures. During oscillation, the total energy of the system is conserved,
\begin{equation}
    E = -\cos \theta + \frac{\dot{\theta}^2}{2}.
\end{equation}
Note that in this notation, $\theta = 0$ is the bottom, so $\theta \in [-\pi,
\pi]$. We would formally derive this by writing down the Lagrangian and making
the Legendre transform, but in the present case if we just identify $p =
\dot{\theta}$ the conjugate momentum to $\theta$ then we find immediately that
$\dot{p} = -\pdil{E}{\theta} = -\sin\theta$ and that $\dot{\theta} = \pdil{E}{p}
= p = \dot{\theta}$. Thus, we can explicitly write:
\begin{align*}
    \dot{\theta}(\theta) &= \sqrt{2(E + \cos \theta)},\\
        &= \sqrt{2\p{\cos\theta - \cos\theta_0}}.
\end{align*}
The period of the pendulum is formally defined such that
\begin{align*}
    P &= 4\int\limits_0^{\theta_0}\rd{t}{\theta}\;\mathrm{d}\theta
\end{align*}
This is the amount of time it takes for the pendulum to go from an initial
condition $\pm \theta_0$ to $0$, so a quarter-period. For sufficiently small
$\theta_0$, the quadrature expression can be expanded
\begin{align*}
    \dot{\theta} &\approx \sqrt{-\theta^2 + \theta_0^2}\\
    P &= 4\int\limits_0^{\theta_0} \frac{1}{\sqrt{\theta_0^2 - \theta^2}}
            \;\mathrm{d}\theta.
\end{align*}
We know this is arcsin, but is it obvious? Actually, yeah:
\begin{align*}
    \int\limits^y\frac{1}{\sqrt{1 - x^2}}\;\mathrm{d}x
        &= \int\limits^{\arcsin(y)}
            \frac{1}{\sqrt{1 - \sin^2u}}\;\mathrm{d}(\sin u),\\
        &= \int\limits^{\arcsin(y)}\mathrm{d}u,\\
        &= \arcsin(y).
\end{align*}
So then
\begin{align*}
    P &= 4\s{\arcsin\p{\frac{\theta}{\theta_0}}}_0^{\theta_0},\\
        &= 2\pi.
\end{align*}
Great.

What about in the nonlinear limit though? In full generality, we have
\begin{align*}
    P &= 4\int\limits_0^{\theta_0}
        \frac{1}{\sqrt{2\p{\cos \theta - \cos \theta_0}}} \;\mathrm{d}\theta.
\end{align*}
In the limit where $\theta_0 \to \pm \pi$, we cannot make any approximations
since $\theta$ will span the full angular interval. However, $\theta_0$
sufficiently close to $\pm \pi$, the unstable points, we recognize that the
dominant contribution to $P$ will be near $\pi$. Thus, let's instead ask the
question: for some fixed $\theta_1 \ll 1$, how long does it take for the
trajectory to reach $\theta_1$ as $\theta_0 \to \pi$? We again should be able to
make expansions now (let $\phi \equiv \pi - \theta$)
\begin{align*}
    P &\gtrsim 4\int\limits_{\phi_0}^{\phi_1}
        \frac{1}{\sqrt{\phi^2 - \phi_0^2}} \;\mathrm{d}\phi.
\end{align*}
Note here that $\phi > \phi_0$. This one is probably a cosh?
\begin{align*}
    \int\limits^y\frac{1}{\sqrt{x^2 - 1}}\;\mathrm{d}x
        &= \int\limits^{\cosh^{-1}(y)}
            \frac{1}{\sqrt{\cosh^2(u) - 1}}\;\mathrm{d}(\cosh(u)),\\
        &= \cosh^{-1}(y),\\
    P &\gtrsim 4\s{\cosh^{-1}\p{\frac{\phi}{\phi_0}}}^{\phi_1}_{\phi_0},\\
        &\gtrsim 4\ln\p{\phi_1 / \phi_0} \sim -4\ln\p{\pi_0}.
\end{align*}
Here, we've made use of the fact that $\cosh(x) \approx \exp(x) / 2$ for large
$x$. Hence, we recover the logarithmic divergence that is expected.

\section{04/15/2023---Distributions of Functions of Random Variables}

I can never remember how to do this, so let me just write it down.

If we have a random variable $X$ and a second random variable $Y$ that satisfies
$y = y(x)$, then the PDF of Y is simple:
\begin{align}
    \int\limits f_Y(y)\;\mathrm{d}y
        &= \int\limits f_X(x)\;\mathrm{d}x,\\
    f_Y(y) &= f_X(x)\rd{x}{y}.
\end{align}

What if we have a random variable $Z$ that is a function of two random variables
$X, Y$ satisfying $z(x, y)$? This is a little trickier, but we need to write
down the CDF
\begin{align}
    \int\limits f_Z(z)\;\mathrm{d}z
        &= \iint\limits f_Y(y)f_X(x)\;\mathrm{d}x\mathrm{d}y.
\end{align}

This is no longer solvable in general (but we can often do well in statistical
cases with moment-generating functions, CLT, and others). But for sufficiently
simple dependencies, we can do this. Let's just consider $z = x + y$, for $x, y
\in \mathcal{U}_{[0, 1]}$. This is then easy to do:
\begin{align}
    \int\limits_0^z f_Z(w)\;\mathrm{d}w
        &= \int\limits_0^{\min(z, 1)}
            \int\limits_{0}
                ^{\min(z - y, 1)}\;\mathrm{d}x\;\mathrm{d}y,\\
        &= \int\limits_0^{\min(z, 1)}
            \min\p{z - y, 1}\;\mathrm{d}y,\\
        &=
        \begin{cases}
            \int\limits_0^z
                z - y\;\mathrm{d}y & z < 1\\[10pt]
            \int\limits_0^{z - 1}
                \;\mathrm{d}y +
            \int\limits_{z - 1}^1
                (z - y)\;\mathrm{d}y & z > 1,
        \end{cases}\\
        &=
        \begin{cases}
            z^2 / 2 & z < 1\\
            (z - 1) + (z - 1/2) - z(z-1) + (z - 1)^2/2 & z > 1,
        \end{cases}\\
    f_Z(z) &=
        \begin{cases}
            z & z < 1\\
            2 - z & z > 1.
        \end{cases}
\end{align}
We can do the same for $z = xy$:

\section{08/21/2023---Change in Mutual Inclination in Hierarchical Triples due to SNe}

We find that when a hierarchical stellar triple has its inner and outer orbits
initially isotropically distributed, the final mutual inclination distribution
is not isotropic, but is depleted near $90^\circ$. We build a simple
quantitative model analogous to this phenomenon and show that it has an exact
solution.

The essence of this behavior is that: a symmetric SNe in the inner orbit results
in an effective kick to the outer orbit in the plane of the inner orbit, denoted
$\vec{v}_{\rm k, eff}$. Only the component of this kick aligned with the outer
orbit normal contributes to realignment of the outer AM\@. Thus,
\begin{equation}
    \Delta I \lesssim \Delta I_{\max}\propto v_{\rm k, eff}\sin I.
\end{equation}
The actual change in $I$ is approximately symmetrically distributed over the
interval $\s{-\Delta I_{\max}, \Delta I_{\max}}$. Note that, strictly speaking,
neither $I$ nor $\cos I$ are uniformly distributed: imagine that the initial AM
is along $\uv{l}_{\rm b, 0}$, then the final AMs are distributed in an
azimuthally symmetric way about $\uv{l}_{\rm b, 0}$. This is closer to a
symmetric distribution in $I$ than $\cos I$ though.

To see what effect this has on the outer inclination, we imagine a diffusion
equation for $I \in [0, \pi]$ with diffusion coefficient $D_0 \sin I$. This can
be thought of as the cumulative effect of infinitely many, infinitesimally small
effective kicks. This has the form
\begin{equation}
    \pd{f}{t} = \pd{}{I}\s{D_0\sin I\pd{f}{I}},
\end{equation}
where $f(t, I)$ is the PDF of $I$ at time $t$. I really just wanted to solve
this PDE lol.

We first consider the steady-state solutions of this PDE\@. One possible family of
solutions requires that
\begin{align}
    D_0\sin I\pd{f}{I} &= C,\\
    -\sin^2I \pd{f}{\cos I} &= \frac{C}{D_0},\\
    \pd{f}{\cos I} &= \frac{C}{D_0\p{\cos^2 I - 1}}.
\end{align}
But since $\arctanh'(x) = (1 - x^2)^{-1}$, we find that this is just
\begin{equation}
    f(\cos I) = \frac{C}{D_0}\arctanh(\cos I).
\end{equation}
Then $C$ can be set by the normalization of $f(t, I)$. The second homogeneous
solution is simply the family of linear solutions $f(t, I) = A \times I$. If the
IC is symmetric, then the symmetry is preserved under evolution, and we can
require that $f'(t, 0) = 0$ at all times. This thus requires that
\begin{equation}
    f\p{\cos I \in [-1, 1]} = \frac{C}{D_0}\abs{\arctanh(\cos I) - \cos I}.
\end{equation}
This works since $\arctanh'(0) = 1$, so the derivative is indeed zero at $\cos I
= 0$, and the solution is symmetric. $C$ is again set by the normalization,
which I'm too lazy to compute. This is thus the steady-state solution, and we
see that it vanishes at the origin and is singular at $\cos I = \pm 1$. This is
indeed the behavior we were beginning to see!

Of course, with just a single kick, we don't evolve to this steady state $f$,
but only a little bit. Nevertheless, this gives a quantitative model reflecting
the depletion near $\cos I = 0$.

\section{02/21/24---Jeremy and Rotations Generated by Andoyer Momenta}

Jeremy asks a simple question, and as always it's a hard one: the three Andoyer
momenta are $p_g=S$, $p_l=S\cos J$, and $p_h=S \cos i$ (not the usual order).
The first is the total spin AM, and the second two are projections along the
body axis and the orbit axis respectively. The question is: why is $\z{p_l, p_h}
= 0$, the PB, when it's clear that rotations about the body and orbit axes do
not commute?

\subsection{Reminder: Standard AM Poisson Brackets}

This was a rabbit hole, and I don't think I have the right answer, but I first
briefly recall what the PB is. For two functions $f\p{q_i, p_i}$ and $g\p{q_i,
p_i}$, we have that
\begin{equation}
    \z{f, g}
        = \sum\limits_i \pd{f}{q_i}\pd{g}{p_i}
            - \pd{f}{p_i}\pd{g}{q_i}.
\end{equation}
The standard results concern the PBs of the angular momenta, given by $\bm{L} =
\bm{r} \times \bm{p}$, or $L_k = \epsilon_{ijk}r_ip_j$. Then, using the standard
Cartesian $\bm{r}$ and $\bm{p}$ as our canonical coordinates, we can evaluate
the PBs for $\bm{L}$:
\begin{align*}
    \z{L_x, L_y}
        &= \sum\limits_m \pd{L_x}{r_m}\pd{L_y}{p_m}
            - \pd{L_x}{p_m}\pd{L_y}{r_m},\\
        &= \sum\limits_m
            \epsilon_{mjx}p_j \epsilon_{myi}r_i
                - \epsilon_{mxi}r_i \epsilon_{mjy}p_j,\\
        &= \sum\limits_m p_jr_i\p{\delta_{jy}\delta_{xi}
            - \delta_{ji}\delta_{xy}}
            - r_ip_j\p{\delta_{xj}\delta_{iy}
                - \delta_{ij}\delta_{xy}},\\
        &= p_yr_x - r_yp_x = L_z.
\end{align*}
In the third line, we've cyclically permuted indicies and used the usual
relation to simplify $\epsilon_{ijk}\epsilon_{imn}$. Of course, this can be
repeated for the other commutators to obtain that $\z{L_i, L_j} =
\epsilon_{ijk}L_k$.

Now, what about for $L^2$? WLOG
\begin{align*}
    \z{L^2, L_z} &= \sum\limits_i L_i\z{L_i, L_z} + \z{L_i, L_z}L_i,\\
        &= -L_x L_y + L_yL_x - L_yL_x + L_xL_y = 0.
\end{align*}
And of course, similarly for the other two components. What about for a general
power of $L$? Well, it's not hard to show that
\begin{align*}
    \z{L^n, L_z}
        &= \sum\limits_m \sum\limits_i
            nL^{n-1}\rd{L}{L_i}\pd{L_i}{q_i}\pd{L_z}{p_i}
            - nL^{n-1}\rd{L}{L_i}\pd{L_i}{p_i}\pd{L_z}{q_i},\\
        &= nL^{n-1}\sum\limits_i\frac{L_i}{L}\z{L_i, L_z},\\
        &= nL^{n-2}\p{L_xL_y - L_yL_x} = 0.
\end{align*}

\subsection{What does it mean to generate rotation?}

This is the key point that I want to belabor, and hopefully be correct on. When
we speak of $L_z$ generating rotations about the $z$ axis, I think that we mean
that there exists a canonical set of coordinates such that $L_z, \phi_z$ are
canonically conjugate. However, in isolation, it means nothing to argue that a
scalar, which is all that $L_z$ is, \emph{generates} any sort of rotation /
action. It is only when we attach it to a Hamiltonian / symplectic manifold that
we can promote the coordinate to an operator and assign an action to it.

In this sense, for the standard Delaunay variables, $(e, L, L_z)$ and $(M,
\omega, \Omega)$ (we write $e = \sqrt{GMa}$ for simplicity), $L_z$ generates
advancement of $\Omega$ at constant $M, \omega$ (and of course constant $e, L,
L_z$). However, there are plenty of rotations about $\uv{z}$ that do not
preserve these variables (such as a torque on the orbit), and the one that $L_z$
generates here can only be defined in the context of the other variables.

Put another way, suppose my particle is initially at Cartesian coordinates $(0,
-1, 0)$. Then $L_z$ will generate rotation about $z$, which corresponds to
motion in the $+\uv{x}$ direction, but it conserves total AM\@. For comparison, in
the original Cartesian coordinates, $p_x$ generates $x$ velocity at constant
$(z, y, p_z, p_y)$, but it does not conserve AM\@. What is the difference between
these two? At the level of the infinitesimal displacement, nothing; we need the
Hamiltonian structure and the other canonical coordinates to distinguish between
the two.

Thus, for the Andoyer system, consisting of $(l, g, h)$, $(p_l, p_g, p_h)$, it
is clear that $p_l$ and $p_h$ generate motion at fixed $(g, h)$ and fixed $(l,
g)$ respectively. The angles $l$ and $h$ are indeed Euler angles describing the
rotational phase about the orbit and body axes respectively, but the motion
generated by $p_l$ and $p_h$ cannot simply correspond to naive rotation about
these axes, and is instead a constrained rotation.

\textbf{After talking to Jeremy}, he points out that his question is motivated
by ``old quantum mechanics'', where we only knew how to quantize very limited
systems since we didn't have the SE until 1926 (while Planck's quantization was
in 1901 or so). When computing the rotational modes of H$_2$O, there is a third
quantum number due to the triaxiality of the molecule, on top of the usual $(l,
m)$ due to $(L^2, L_z)$. But we can imagine describing its orientation in
Andoyer variables instead; how would the quantization proceed in that case? It
would then appear that the canonical momenta are to be promoted to operators,
and then quantized; how do the operators commute then? We didn't get this far,
but I thought that perhaps one just quantizes the three component rotations;
maybe that's what \url{https://arxiv.org/pdf/2211.11347.pdf} is doing for one of
the Euler angles? Since at least the Andoyer angles are Euler angles, though are
a mixed set of them. Of course Jeremy's questions are hard to answer\dots

\section{Mass Loss Induced Eccentricity}

Consider a particle on a circular orbit with $a_0$ around a central mass
$M_\star$ and initial mass $M$. It loses $\delta m$, ejected behind it with
velocity $v_{\rm ej}$; what is the new sma and eccentricity?

First, we note that the new mass of the particle, $M' = M - \delta m$, is now
moving at velocity $v' = v_0 + \delta v$ where
\begin{align}
    v_0 &= \sqrt{GM_\star / a_0},\\
    \delta v &= \frac{\delta m}{M'}v_{\rm ej}.
\end{align}

Then, computing the new angular momentum of the particle (which now has sma
$a'$), we have (factoring out the particle mass)
\begin{align}
    \sqrt{GM_\star a'(1 - e^2)} &= a_0v',\\
    \frac{GM_\star}{a_0}\frac{a'}{a_0}(1 - e^2) &= (v')^2,\\
    1 - e^2 &= \frac{(v')^2}{v_0^2}\frac{a_0}{a'}.
\end{align}
On the other hand, the energy gives us
\begin{align}
    \frac{(v')^2}{2} - \frac{GM_\star}{a_0} &= -\frac{GM_\star}{2a'},\\
    \frac{(v')^2}{v_0^2} - 2 &= -\frac{a_0}{a'}.
\end{align}
Combining, we find (define $\Delta \equiv \delta v / v_0$)
\begin{align}
    1 - e^2 &= \frac{(v')^2}{v_0^2}\p{2 - \frac{(v')^2}{v_0^2}},\\
        &= \p{1 + \Delta}^2\p{2 - \p{1 + \Delta}^2},\\
        &= 2\p{1 + 2\Delta + \Delta^2}
            - \p{1 + 4\Delta + 6\Delta^2 + 4\Delta^3 + \Delta^4},\\
        &= 1 - 4\Delta^2 - 4\Delta^3 - \Delta^4,\\
    e &\approx 2\Delta = 2\frac{\delta m}{M'}\frac{v_{\rm ej}}{v_0}.
\end{align}

\section{Tidal Dissipation into CS2?}

Note that the weak friction equations give a nonzero tidal equilibrium obliquity
\begin{equation}
    \rd{\theta}{t} = \frac{1}{t_{\rm s}}
        \p{\frac{2n}{\Omega_{\rm s}} - \cos \theta}.
\end{equation}
This was used by Valente \& Correia 2022, in conjunction with a spin-orbit
resonance (non-secular) to excite large obliquities for eccentric orbits, where
these asynchronous SORs are common. So maybe this is legit.

If so, what is the condition for CS2 capture? Well, we know that the resonance
width is
\begin{align}
    \cos \theta_{\rm sep}
        &\approx \eta \cos I \pm \sqrt{2\eta \sin I
            \p{1 - \cos \phi}},\\
    \Delta \cos\theta \sim \sqrt{\eta_{\rm sync}\frac{n}{\Omega_{\rm s}}
        \sin I}.
\end{align}
The condition then for guaranteed capture is
\begin{align}
    \frac{2n}{\Omega_{\rm s}} &\lesssim \sqrt{\eta_{\rm sync}
        \frac{n}{\Omega_{\rm s}}\sin I},\\
    \frac{4n}{\Omega_{\rm s}} &\lesssim \eta_{\rm sync}\sin I,\\
    \Omega &\gtrsim \frac{4n}{\eta_{\rm sync}\sin I}.
\end{align}
However, recalling that $\eta_{\rm sync} \lesssim 0.7$ is required for large
obliquities---well, $\eta_{\rm sync} \leq \eta_{\rm c}$, where
\begin{equation}
    \eta_{\rm c} = \p{\cos^{2/3}I + \sin^{2/3}I}^{-3/2},
\end{equation}
then since $\eta_{\rm c} \in [0.5, 1]$, this is the typical value of $\eta_{\rm
c}$ as well. Thus, adopting fiducial values $\eta_{\rm sync} \sim \sin I \sim
0.3$, we obtain that
\begin{equation}
    \Omega_{\rm s} \gtrsim 40n.
\end{equation}

Recall that planets are born near critical rotation, so
\begin{align}
    \Omega_{\rm s, 0} &\approx \sqrt{\frac{Gm}{R^3}},\\
    \frac{\Omega_{\rm s, 0}}{n}
        &= \sqrt{\frac{ma^3}{M_\star R^3}},\\
        &=
            6000
            \p{\frac{(m/M_\star)/(m_\oplus/M_\odot)}{\scinot{3}{-6}}}^{1/2}
            \p{\frac{(a/R) / (\mathrm{AU} / R_\oplus)}{\scinot{2.3}{4}}}^{3/2}.
\end{align}
Of course, these values are quite optimistic, but it's clear that planets have
to spin down substantially before reaching synchronization, i.e.\ over many
$t_{\rm s}$, and so there is plenty of time to experience obliquity excitement.

\subsection{Do we believe Obliquity Excitation?}

We start with the L12 Eq.~(37)
\begin{equation}
    S\rd{\theta}{t} = -T_x + \frac{S}{L}\p{T_z\sin\theta - T_x\cos\theta}.
\end{equation}
Here, $\theta$ is the obliquity. In general,
\begin{equation}
    \frac{S}{L} = k\p{\frac{R}{a}}^2\frac{\Omega_{\rm s}}{n} \ll 1,
\end{equation}
so the obliquity evolution is set by $T_x$. Recall that this is the
component of the torque exerted by the companion on the primary that is normal
to the rotation axis and is radial (i.e.\ not azimuthal, does not contribute to
precession).

When all the tidal lags are equal to $\tau$, L12 finds that
\begin{equation}
    T_x = \frac{6\pi}{5}T_0\sin\theta\p{2\Omega - \Omega_{\rm s}\cos\theta}
        \tau.
\end{equation}
Of course, this is negative when $\Omega_{\rm s} > 2\Omega / \cos\theta$, but
this is just the standard equilibrium tidal theory and result. Can we be more
general?

Let's recall the Gladman96 expression
\begin{equation}
    \bm{T}_{\rm tide}
        = \frac{3k_2Gm_{\rm p}^2R^5}{a^6}
            \p{\uv{\rho} \cdot \uv{r}}
            \p{\uv{\rho} \times \uv{r}},
\end{equation}
where
\begin{equation}
    \bm{\rho} \approx \uv{r} - \p{n\uv{l} \times \uv{r}}\tau
        +\p{\Omega_{\rm s}\uv{k} \times \uv{r}}\tau,
\end{equation}
is the time-lagged position (by $\tau$) of the perturber in the rest frame of
the primary. It is thus interesting to ask: if in general, a torque scales with
$\uv{\rho} \times \uv{r}$, when does it excite the obliquity? This could have
been interesting, but Gladman already showed that the torque, absent its
component along $\uv{k}$, is $\propto -\Omega_{\rm s} \cos\theta + 2n$, as
above.

The condition, however, is likely to generalize to: if the dominant, or all,
tidal frequencies $m'\Omega - m\Omega_{\rm s}$ are negative, then the primary's
obliquity is excited. This is simple to understand: if the perturber is trying
to spin the primary down, but it's misaligned from the equator, then it can only
exert forces in the plane of the orbit, i.e.\ along $\uv{l}$. If $\uv{k}$ is
initially close to $\uv{l}$, then the only despinning torque along $\uv{l}$ will
tend to drive $\uv{k}$ \emph{away} from $\uv{l}$, while spinning it down (draw
some arrows).

For a more simple example, call $\uv{l} = \uv{z}$, then differentiating
$\cos\theta = L_z / L$ gives
\begin{align}
    \rd{\cos\theta}{t} &= \frac{1}{L}T_z - \frac{L_z}{L^2}T,\\
        &= \frac{LT_z - L_zT}{L^2},\\
        &= \frac{T}{L^2}\p{1 - \cos\theta}.
\end{align}
Here, $T$ is the component of the torque along $\uv{l}$; it must be negative to
be a despinning torque, so $\cos\theta$ grows.

Maybe we can assert that the dynamical tide generally also acts to increase
obliquities as long as the pattern frequency is negative? TODO\@.

\section{Tidal Dissipation with General Rheology}

It's about time that we learned this. We try to understand the problem from the
angle of Lai 2012 and Correia \& Valente 2022.

Let's start by trying to find the common ground. We start with Dong's two
expressions, and make the substition $x = \cos \theta$, $y = \sin\theta$:
\begin{align}
    T_z
        ={}&
            \frac{3}{32}T_0 \Big[
                (1 + x)^4 b\p{2n - 2\omega}
                + 2y^2(1 + x)^2 b\p{2n - \omega}\nonumber\\
                &- 2y^2(1 - x)^2 b\p{2n + \omega}
                - (1 - x)^4 b\p{2n + 2\omega}
            \Big]\nonumber\\
        &-
            \frac{3}{8} T_0\Big[
                y^4 b(2\omega)
                + 2y^2x^2 b(\omega)
            \Big],\\
    T_x
        ={}&
            \frac{3}{32}T_0 \Big[
                y (1 + x)^3 b\p{2n - 2\omega}
                + 2y(1 + x)^2(2 - x)b(2n - \omega)\nonumber\\
                &+ 3y^3 b(2n)
                + 2y(1 - x)^2(2 + x)b(2n + \omega)
                + y (1-x)^3 b(2n + 2\omega)
            \Big]\nonumber\\
        &
            + \frac{3}{8}T_0 \Big[
                y^3x b(2\omega)
                + 2yx^3 b(\omega)
            \Big].
\end{align}
Here, we've used $n$ to be the mean motion, $\omega$ to be the spin rate, and
$b(m'\Omega - m\Omega_s) = 4\pi(m'\Omega - m\Omega_s)\tau_{mm'} / 5$ to be the
imaginary part of the Love number at this frequency. This is Correia \&
Valente's notation, since in their Paper I S2.7.2, we have that the weak
friction model corresponds to the Love distribution
\begin{align}
    k_2(t) &= k_{\rm f} \delta\p{t - \Delta t},\\
    \hat{k}_2(\sigma) &= k_{\rm f}e^{-i\sigma \Delta t},\\
    b(\sigma) \equiv \Im(\tilde{k_2})(\sigma)
        &= k_{\rm f}\sigma \Delta t,
\end{align}
for tidal time lag $\Delta t$. In Dong's notation, $4\pi\tau_{mm'} / 5$ eventually
becomes $k_2\Delta t$, so this should be the right correspondence.

We should check whether this agrees with Eqs~(12--13) of VC22, at zero
eccentricity. The signs etc are:
\begin{align}
    -T_z = T_s
        ={}&
            \frac{3K}{32} \Big[
                2b(\omega - 2n)y^2(1 + x)^2
                + 2b(\omega + 2n)y^2(1 - x)^2\nonumber\\
                &+ b(2\omega - 2n)(1 + x)^4
                + b(2\omega + 2n)(1 - x)^4
            \Big]\nonumber\\
        &+
            \frac{3K}{32} \Big[
                2b(\omega)4y^2x^2
                + b(2\omega)4y^4
            \Big],\\
    -T_x = \frac{T_q}{y}
        ={}&
            \frac{3K}{32} \Big[
                3b(-2n)y^2
                + 2b(\omega - 2n)(1 + x)^2 (2 - x)
                - 2b(\omega + 2n)(1 - x)^2 (2 + x) \nonumber\\
                &+ b(2\omega - 2n)(1 + x)^3
                -b(2\omega + 2n)(1 - x)^3
            \Big]\nonumber\\
        &+
            \frac{3K}{32} \Big[
                -8x^3 b(\omega)
                -4 x(1-x^2) b(2\omega)
            \Big].
\end{align}
Note that $T_0 = GM_2^2R^5/a^6 = K$. The agreement with Dong's equations can
only be obtained in the constant time lag model, since Dong has factored out a
few signs here and there. But if indeed the CTL model is assumed, then the two
expressions agree, miraculously:
\begin{align}
    T_{z,VC22}\frac{32}{3T_0}
        ={}&
            \Big[
                2b(2n - \omega)y^2(1 + x)^2
                - 2b(2n + \omega)y^2(1 - x)^2\nonumber\\
                &+ b(2n - 2\omega)(1 + x)^4
                - b(2n + 2\omega)(1 - x)^4
            \Big]\nonumber\\
        &-
            \Big[
                8b(\omega)y^2x^2
                + 4b(2\omega)y^4
            \Big],\\
    T_{x, VC22}\frac{32}{3T_0}
        ={}&
            \Big[
                3b(2n)y^3
                + 2b(2n - \omega)(1 + x)^2 (2 - x)y
                + 2b(2n + \omega)(1 - x)^2 (2 + x)y \nonumber\\
                &+ b(2n - 2\omega)(1 + x)^3y
                +b(2n + 2\omega)(1 - x)^3y
            \Big]\nonumber\\
        &+
            \Big[
                8x^3y b(\omega)
                + 4 xy^3 b(2\omega)
            \Big].
\end{align}
Again, if we set $b(\sigma) = 4\pi \sigma \tau_{mm'}/5$ in these expressions, we
recover Lai 2012.

\subsection{Pseudosynchronous 2:1 Feature in Maxwell}

Now, the question is: if we assume a Maxwell viscoelastic rheology, in the very
not-CTL regime, why is there a pseudosynchronous 2:1 feature? Well, in the
Maxwell rheology, (CV22 2.7.3)
\begin{align}
    \hat{k}_2(\sigma)
        &= k_{\rm f}\frac{1 + i\sigma \tau_{e}}{1 + i\sigma \tau},
\end{align}
where $\tau_{\rm e}$ is the elastic/Maxwell relaxation time, and $\tau =
\tau_{\rm e} + \tau_{\rm v}$ the viscous time. In particular, $k_{\rm f} =
\hat{k}_2(0)$ is the fluid Love number (perturbations are slow), while the
elastic Love number can be defined $k_{\rm e} = \hat{k}_2(\infty) = k_{\rm f}
\tau_{\rm e} / (\tau_{\rm e} + \tau_{\rm v})$. In the case of the Earth, $k_{\rm
e} \approx 0.3$ and $k_{\rm f} \approx 0.9$.

Now, we can just calculate the imaginary piece of $\hat{k}_2$, and find (VC22 Eq
21)
\begin{equation}
    b(\sigma) = k_{\rm f}\frac{\sigma \tau_{\rm e}}{1 + (\sigma \tau)^2}
        = \p{k_{\rm f} - k_{\rm e}}
            \frac{\sigma \tau}{1 + (\sigma \tau)^2}.
\end{equation}
Then, in the elastic limit $\sigma \tau \gg 1$, $b(\sigma) \approx \p{k_{\rm f}
- k_{\rm e}} / \sigma \tau$. For the estimates of VC22, $\tau_e \gtrsim
50\;\mathrm{yr}$ and $\tau \sim 3\tau_e$ for Earth-like planets, and since
$\sigma \sim n$, we should be in the regime where $\sigma \tau \gg 1$. It's
worth noting that if $\tau$ is much shorter, that the planet would likely flow
in response to the NPAR\@. To recover the fluid limit, we simply need to take
the limit $\tau_{\rm e} \to 0$, and since $\tau_{\rm v}$ is very fast, we will
recover the standard fluid result $\hat{k}_2(\sigma) \approx k_{\rm f}\p{1 -
i\sigma \tau_{\rm v}}$.

Then, using this approximation, the spin evolution of the planet (which depends
on $T_z / C$), goes like
\begin{equation}
    \rd{\omega}{t} \propto
        T_{z}\frac{32}{3T_0}\frac{\tau}{k_{\rm f} - k_{\rm e}}
        \approx
                \frac{2y^2(1 + x)^2}{2n - \omega}
                - \frac{2y^2(1 - x)^2}{2n + \omega}
                + \frac{(1 + x)^4}{2n - 2\omega}
                - \frac{(1 - x)^4}{2n + 2\omega}
                - \frac{8y^2x^2 + 2y^4}{\omega}.
\end{equation}
Of course, this cannot be exactly true (this is singular every time $\omega =
\s{-2,2}n$), and there is some softening in $b(\sigma)$ that we've dropped. It's
clear that every time $\dot{\omega} = 1 / \p{n - \omega}$, we have a stable
equilibrium, and the opposite sign is unstable. Thus, $\omega = \z{0, 1, 2}n$
are unconditionally stable in the fully elastic limit?

So this means that, if we instead have a planet experiencing tidal dissipation
not with the CTL but with a Maxwell rheology, the planet's spindown can stall at
2:1. Based on our results above, this would imply that the planet's $J$ is not
excited. So in order for our results to apply, we need a permanently deformed
planet that nevertheless has $\sigma \tau \ll 1$.

In the case of the Earth, typical values for the mantle viscosity and rigidity
($\mu$, also the shear modulus) suggest that $\tau_{\rm e} \sim
400\;\mathrm{yr}$ (CV22, see also Storch \& Lai 2014). However, it's worth
noting that the rigidity alone sets the maximum triaxiality of planets (Zanazzi
2018). Thus, for sufficiently viscous planets (small $\eta$), we may still have
$\tau_{\rm e} = \eta / \mu$ small enough that we're in the fluid limit for tidal
perturbations while being sufficiently materially strong to sustain deformation.
In this limit, the equations that we have used will hold.

\section{Tides with Fluid Envelope}

Question: for a planet w/ thin fluid envelope (by mass), it affects the
dissipation of the rocky core, since the tidal bulge of the envelope will shield
the perturbing potential somewhat. Can we estimate this effect? Moreover, how
much does this effect depend on the radial extent of the envelope; can we check
the effect of tidal inflation on the dissipation of a SN that is a rocky core +
gaseous envelope?

\end{document}

